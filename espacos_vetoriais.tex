%!TEX program = xelatex
%!TEX root = IAL.tex

\chapter{Espaços Vetoriais}

Em todo este cap{\'\i}tulo $\cp{K}$ denotar\'a um corpo.

\begin{definicao}
	Um conjunto	n\~ao vazio $V$ \'e um \textbf{espa\c{c}o vetorial}\index{Espaço Vetorial} sobre um corpo $\cp{K}$ se em seus elementos,
	chamados \textbf{vetores}\index{Espaço Vetorial!vetores}, estiverem definidas duas opera\c{c}\~oes satisfazendo:
	\begin{itemize}
		\item[A)] A cada par $u$, $w \in V$ corresponde um vetor $u + w \in V$, chamado \textbf{soma} de $u$ e $w$, de modo que:
		\item[A1)] $u + w = w + u$, para todos $u$, $w \in V$;
		\item[A2)] $(u + w) + x = u + (w + x)$, para todos $u$, $w$, $x \in V$;
		\item[A3)] Existe em $V$ um vetor, denominado \textbf{vetor nulo}\index{Espaço Vetorial!vetor nulo} e denotado por $0_V$, tal que
			\[
				0_V + u = u
			\]
			para todo $u \in V$.
		\item[A4)] Para cada vetor $u \in V$, existe um vetor em $V$, denotado por $-u$ e chamado de \textbf{vetor oposto},\index{Espaço Vetorial!vetor oposto} tal que
			\[
				u + (-u) = 0_V.
			\]
		\item[M)] A cada par $\alpha \in \cp{K}$ e $u \in V$, corresponde um vetor $\alpha \cdot u \in V$, denominado \textbf{produto por escalar}\index{Espaço Vetorial!produto por escalar} de $\alpha$ por $u$ de modo que:
		\item[M1)] $(\alpha\beta)\cdot u = \alpha(\beta\cdot u)$ para todos $\alpha$, $\beta \in \cp{K}$ e todo $u \in V$;
		\item[M2)] $1_\cp{K}\cdot u = u$ para todo $u \in V$, onde $1_\cp{K}$ \'e o elemento neutro da multiplica\c{c}\~ao em $\cp{K}$.
		\item[D1)] $\alpha\cdot(u + w) = \alpha\cdot u + \alpha\cdot w$, para todo $\alpha \in \cp{K}$ e todos $u$, $w \in V$;
		\item[D2)] $(\alpha + \beta)\cdot u = \alpha\cdot u + \beta\cdot u$, para todos $\alpha$, $\beta \in \cp{K}$ e todo $u \in V$.
	\end{itemize}
\end{definicao}

\begin{observacao}
	Vamos usar a express\~ao $\cp{K}$-\textbf{espa\c{c}o vetorial} para nos referir a um espa\c{c}o vetorial $V$ sobre um corpo $\cp{K}$.
\end{observacao}

\begin{exemplo}
	\begin{enumerate}[label={\arabic*})]
		\item Seja $\cp{K} = \real$ um corpo. Considere o conjunto
		      \[
			      \real^3 = \underbrace{\real \times \real \times \real}_{3 vezes} = \{(a_1, a_2, a_3) \mid a_i \in \real, i =1, 2, \dots, n\}
		      \]
		      e defina
		      \begin{itemize}
			      \item $(a_1, a_2, a_3) + (b_1, b_2, b_3) = (a_1 + b_1, a_2 + b_2, a_3 + b_3)$ para todos $(a_1, a_2, a_3)$, $(b_1, b_2, b_3) \in \real^3$;
			      \item $\alpha (a_1, a_2, a_3) = (\alpha a_1, \alpha a_2, \alpha a_3)$ para todo $\alpha \in \real$ e todo $(a_1, a_2, a_3) \in \real^3$.
			            Com estas opera\c{c}\~oes $\real^3$ \'e um espa\c{c}o vetorial sobre $\real$.
		      \end{itemize}
		      \begin{solucao}
			      De fato,
			      \begin{enumerate}
				      \item[A1)] $(a_1, a_2, a_3) + (b_1, b_2, b_3) = (a_1 + b_1, a_2 + b_2, a_3 + b_3) = (b_1 + a_1, b_2 + a_2, b_3 + a_3) = (b_1, b_2, b_3) + (a_1, a_2, a_3)$, para todos $(a_1, a_2, a_3)$, $(b_1, b_2, b_3) \in \real^3$.

				      \item[A2)] $[(a_1, a_2, a_3) + (b_1, b_2, b_3)] + (c_1, c_2, c_3) = (a_1 + b_1, a_2 + b_2, a_3 + b_3) + (c_1, c_2, c_3) = ((a_1 + b_1) + c_1, (a_2 + b_2) + c_2, (a_3 + b_3) + c_3) = (a_1 + (b_1 + c_1), a_2 + (b_2 + c_2), a_3 + (b_3 + c_3)) = (a_1, a_2, a_3) + (b_1 + c_1, b_2 + c_2, b_3 + c_3) = (a_1, a_2, a_3) + [(b_1, b_2, b_3) + (c_1, c_2, c_3)]$, para todos $(a_1, a_2, a_3)$, $(b_1, b_2, b_3)$, $(c_1, c_2, c_3) \in \real^3$.

				      \item[A3)] Tome $0_V = (0, 0, 0)$. Ent\~ao para todo $(a_1, a_2, a_3) \in \real^3$ temos
					      \[
						      (a_1, a_2, a_3) + 0_V = (a_1, a_2, a_3) + (0, 0, 0) = (a_1 + 0, a_2 + 0, a_3 + 0) = (a_1, a_2, a_3).
					      \]
					      Logo $0_V = (0, 0, 0)$ \'e o vetor nulo de $\real^3$.

				      \item[A4)] Dado $u = (a_1, a_2, a_3) \in \real^3$, tome $-u = (-a_1, -a_2, -a_3) \in \real^3$. Assim
					      \[
						      u + (-u) = (a_1, a_2, a_3) + (-a_1, -a_2, -a_3) = (a_1 - a_1, a_2 - a_2, a_3 - a_3) = (0, 0, 0) = 0_V.
					      \]
					      Logo $-u = (-a_1, -a_2, -a-3)$ é o vetor oposto de $u = (a_1, a_2, a_3)$ em $\real^3$.

				      \item[M1)] Dados $\alpha$, $\beta \in \real$ e $u = (a_1, a_2, a_3) \in \real^3$ temos:
					      \begin{align*}
						      (\alpha\beta)\cdot u & = (\alpha \beta)\cdot (a_1, a_2, a_3) = ((\alpha\beta)a_1, (\alpha\beta)a_2, (\alpha\beta)a_3) \\ &= (\alpha(\beta a_1), \alpha(\beta a_2), \alpha(\beta a_3)) = \alpha\cdot(\beta a_1, \beta a_2, \beta a_3)\\ & = \alpha\cdot(\beta\cdot(a_1, a_2, a_3)) = \alpha\cdot(\beta\cdot u)
					      \end{align*}

				      \item[M2)] $1_\real \cdot (a_1, a_2, a_3) = 1 \cdot (a_1, a_2, a_3) = (1\cdot a_1, 1\cdot a_2, 1\cdot a_3) = (a_1, a_2, a_3)$ para todo $(a_1, a_2, a_3) \in \real^3$.

				      \item[D1)] Dados $\alpha \in \real$ e $u = (a_1, a_2, a_3)$, $w = (b_1, b_2, b_3) \in \real^3$ temos:
					      \begin{align*}
						      \alpha\cdot(u + w) & = \alpha\cdot[(a_1, a_2, a_3) + (b_1, b_2, b_3)] = \alpha\cdot(a_1 + b_1, a_2 + b_2, a_3 + b_3) \\ &= (\alpha(a_1 + b_2), \alpha(a_2 + b_2), \alpha(a_3 + b_3))\\ &= (\alpha a_1 + \alpha b_1, \alpha a_2 + \alpha b_2, \alpha a_3 + \alpha b_3) \\ &= (\alpha a_1, \alpha a_2, \alpha a_3) + (\alpha b_1, \alpha b_2, \alpha b_3)\\ &= \alpha\cdot(a_1, a_2, a_3) + \alpha\cdot(b_1, b_2, b_3) \\ &= \alpha\cdot u + \alpha\cdot w
					      \end{align*}

				      \item[D2)] Sejam $\alpha$, $\beta \in \real$ e $u = (a_1, a_2, a_3) \in \real^3$. Temos
					      \begin{align*}
						      (\alpha + \beta)\cdot u & = (\alpha + \beta)\cdot(u_1, u_2, u_ 3) = ((\alpha + \beta)a_1, (\alpha + \beta)a_2, (\alpha + \beta)a_3) \\ &= (\alpha a_1 + \beta a_1, \alpha a_2 + \beta a_2, \alpha a_3 + \beta a_3) \\ &= (\alpha a_1, \alpha a_2, \alpha a_3) + (\beta a_1, \beta a_2, \beta a_3) \\ &= \alpha\cdot(a_1, a_2, a_3) + \beta\cdot(a_1, a_2, a_3) \\ &= \alpha\cdot u + \beta\cdot u
					      \end{align*}
			      \end{enumerate}
			      Portanto $V = \real^3$ \'e um $\real$-espa\c{c}o vetorial.
		      \end{solucao}

		\item De modo geral, seja $\cp{K}$ um corpo. Considere o conjunto
		      \[
			      \cp{K}^n = \underbrace{\cp{K} \times \cp{K} \times \cdots \times \cp{K}}_{n\ vezes} = \{(a_1, a_2,\dots,a_n) \mid a_i \in \cp{K}, i =1, 2, \dots, n\}
		      \]
		      e defina
		      \begin{itemize}
			      \item $(a_1, a_2, \dots, a_n) + (b_1, b_2, \dots,b_n) = (a_1 + b_1, a_2 + b_2,\dots, a_n + b_n)$ para todos $(a_1, a_2, \dots,a_n)$ ,$(b_1, b_2, \dots,b_n) \in \cp{K}^n$;
			      \item $\alpha (a_1, a_2, \dots,a_n) = (\alpha a_1, \alpha a_2, \dots, \alpha a_n)$ para todo $\alpha \in \cp{K}$ e todo $(a_1, a_2, \dots, a_n) \in \cp{K}^n$.
			            Com estas opera\c{c}\~oes $\cp{K}^n$ \'e um espa\c{c}o vetorial sobre $\cp{K}$. Assim temos:
			            \begin{itemize}
				            \item $\rac^n$ \'e um espa\c{c}o vetorial sobre $\rac$;
				            \item $\real^n$ \'e um espa\c{c}o vetorial sobre $\real$;
				            \item $\complex^n$ \'e um espa\c{c}o vetorial sobre $\complex$.
			            \end{itemize}
		      \end{itemize}

		\item $\complex^n$ \'e um espa\c{c}o vetorial sobre $\real$ se definirmos:
		      \begin{itemize}
			      \item $(a_1, a_2, \dots, a_n) + (b_1, b_2, \dots,b_n) = (a_1 + b_1, a_2 + b_2,\dots, a_n + b_n)$ para todos $(a_1, a_2, \dots,a_n)$ ,$(b_1, b_2, \dots,b_n) \in \complex^n$;
			      \item $\alpha (a_1, a_2, \dots,a_n) = (\alpha a_1, \alpha a_2, \dots, \alpha a_n)$ para todo $\alpha \in \real$ e todo $(a_1, a_2, \dots, a_n) \in \complex^n$.
		      \end{itemize}

		\item O conjunto $\rac$ \'e um espa\c{c}o vetorial sobre $\rac$, mas n\~ao \'e um espa\c{c}o vetorial sobre $\real$. (Por qu\^e?)

		\item Considere conjunto das matrizes
		      \[
			      \cp{M}_{2 \times 3}(\rac) = \left\{\begin{pmatrix}a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} \mid a_{ij} \in \rac, i = 1, 2; j = 1, 2, 3\right\}.
		      \]
		      Então $\cp{M}_{2\times 2}(\rac)$ é um espa\c{c}o vetorial sobre $\rac$, com a soma usual de matrizes e a multiplica\c{c}\~ao por escalar usual.
		      \begin{solucao}
			      De fato,
			      \begin{itemize}
				      \item[A1)] Sejam
					      \[
						      A = \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix},
						      B = \begin{pmatrix} b_{11} & b_{12} & b_{13}\\b_{21} & b_{22} & b_{23}\end{pmatrix}.
					      \]
					      Temos:
					      \begin{align*}
						      A + B & = \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} + \begin{pmatrix} b_{11} & b_{12} & b_{13}\\b_{21} & b_{22} & b_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix} a_{11} + b_{11} & a_{12} + b_{12} & a_{13} + b_{13}\\a_{21} + b_{21} & a_{22} + b_{22} & a_{23} + b_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix} b_{11} + a_{11} & b_{12} + a_{12} & b_{13} + a_{13}\\b_{21} + a_{21} & b_{22} + a_{22} & b_{23} + a_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix} b_{11} & b_{12} & b_{13}\\b_{21} & b_{22} & b_{23}\end{pmatrix} + \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix}
						      \\ &= B + A
					      \end{align*}

				      \item[A2)] Sejam
					      \[
						      A = \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix},
						      B = \begin{pmatrix} b_{11} & b_{12} & b_{13}\\b_{21} & b_{22} & b_{23}\end{pmatrix},
						      C = \begin{pmatrix} c_{11} & c_{12} & c_{13}\\c_{21} & c_{22} & c_{23}\end{pmatrix}.
					      \]
					      Temos:
					      \begin{align*}
						      (A + B) + C & = \left(\begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} +
						      \begin{pmatrix} b_{11} & b_{12} & b_{13}\\b_{21} & b_{22} & b_{23}\end{pmatrix}\right) +
						      \begin{pmatrix} c_{11} & c_{12} & c_{13}\\c_{21} & c_{22} & c_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix} a_{11} + b_{11} & a_{12} + b_{12} & a_{13} + b_{13}\\a_{21} + b_{21} & a_{22} + b_{22} & a_{23} + b_{23}\end{pmatrix} +
						      \begin{pmatrix} c_{11} & c_{12} & c_{13}\\c_{21} & c_{22} & c_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix} (a_{11} + b_{11}) + c_{11} & (a_{12} + b_{12}) + c_{12} & (a_{13} + b_{13}) + c_{13}\\(a_{21} + b_{21}) + c_{21} & (a_{22} + b_{22}) + c_{22} & (a_{23} + b_{23}) + c_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix} a_{11} + (b_{11} + c_{11}) & a_{12} + (b_{12} + c_{12}) & a_{13} + (b_{13} + c_{13})\\a_{21} + (b_{21} + c_{21}) & a_{22} + (b_{22} + c_{22}) & a_{23} + (b_{23} + c_{23})\end{pmatrix}
						      \\ &= \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} + \begin{pmatrix} b_{11} + c_{11} & b_{12} + c_{12} & b_{13} + c_{13}\\b_{21} + c_{21} & b_{22} + c_{22} & b_{23} + c_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} +
						      \left(\begin{pmatrix} b_{11} & b_{12} & b_{13}\\b_{21} & b_{22} & b_{23}\end{pmatrix} +
						      \begin{pmatrix} c_{11} & c_{12} & c_{13}\\c_{21} & c_{22} & c_{23}\end{pmatrix}\right)
						      \\ &= A + (B + C).
					      \end{align*}

				      \item[A3)] Tome
					      \[
						      0_V = \begin{pmatrix}0 & 0 & 0\\0 & 0 & 0\end{pmatrix}.
					      \]
					      Para toda matriz
					      \[
						      A = \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix},
					      \]
					      temos
					      \begin{align*}
						      A + 0_V & = \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} +
						      \begin{pmatrix}0 & 0 & 0\\0 & 0 & 0\end{pmatrix}
						      = \begin{pmatrix}a_{11} + 0 & a_{12} + 0 & a_{13} + 0\\a_{21} + 0  & a_{22} + 0 & a_{23} + 0\end{pmatrix}
						      \\ &= \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} = A.
					      \end{align*}
					      Portanto a matriz
					      \[
						      0_V = \begin{pmatrix}0 & 0 & 0\\0 & 0 & 0\end{pmatrix}
					      \]
					      é o vetor nulo.

				      \item[A4)] Dada
					      \[
						      A = \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} \in \cp{M}_{2 \times 3}(\rac),
					      \]
					      tome
					      \[
						      -A = \begin{pmatrix} -a_{11} & -a_{12} & -a_{13}\\-a_{21} & -a_{22} & -a_{23}\end{pmatrix} \in \cp{M}_{2 \times 3}(\rac).
					      \]
					      Assim
					      \begin{align*}
						      A + (-A) & = \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} +
						      \begin{pmatrix} -a_{11} & -a_{12} & -a_{13}\\-a_{21} & -a_{22} & -a_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix} a_{11} - a_{11} & a_{12} - a_{12} & a_{13} - a_{13}\\a_{21} - a_{21} & a_{22} - a_{22} & a_){23} - a_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix}0 & 0 & 0\\0 & 0 & 0\end{pmatrix} = 0_V.
					      \end{align*}
					      Logo a matriz
					      \[
						      -A = \begin{pmatrix} -a_{11} & -a_{12} & -a_{13}\\-a_{21} & -a_{22} & -a_{23}\end{pmatrix}
					      \]
					      é o vetor oposto.

				      \item[M1)] Sejam $\alpha$, $\beta \in \rac$ e
					      \[
						      A = \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} \in \cp{M}_{2 \times 3}(\rac).
					      \]
					      Então:
					      \begin{align*}
						      (\alpha\beta)\cdot A & = (\alpha\beta)\begin{bmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{bmatrix}
						      \\ &=	\begin{bmatrix} (\alpha\beta)a_{11} & (\alpha\beta)a_{12} & (\alpha\beta)a_{13}\\(\alpha\beta)a_{21} & (\alpha\beta)a_{22} & (\alpha\beta)a_{23}\end{bmatrix}
						      \\ &=	\begin{bmatrix} \alpha(\beta a_{11}) & \alpha(\beta a_{12}) & \alpha(\beta a_{13})\\\alpha(\beta a_{21}) & \alpha(\beta a_{22}) & \alpha(\beta a_{23})\end{bmatrix}
						      \\ &=	\alpha\cdot\begin{bmatrix} \beta a_{11} & \beta a_{12} & \beta a_{13}\\\beta a_{21} & \beta a_{22} & \beta a_{23}\end{bmatrix}
						      \\ &=	\alpha\cdot\left(\beta\cdot\begin{bmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{bmatrix}\right)
						      \\ &= \alpha\cdot(\beta\cdot A)
					      \end{align*}

				      \item[M2)] Seja $1 \in \rac$ e
					      \[
						      A = \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} \in \cp{M}_{2 \times 3}(\rac).
					      \]
					      Temos
					      \begin{align*}
						      1\cdot A & = \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix} 1\cdot a_{11} & 1\cdot a_{12} & 1\cdot a_{13}\\1\cdot a_{21} & 1\cdot a_{22} & 1\cdot a_{23}\end{pmatrix}
						      \\ &= \begin{pmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{pmatrix} = A.
					      \end{align*}

				      \item Sejam $\alpha \in \rac$ e
				            \[
					            A = \begin{bmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{bmatrix} \in \cp{M}_{2 \times 3}(\rac),
					            B = \begin{bmatrix} b_{11} & b_{12} & b_{13}\\b_{21} & b_{22} & b_{23}\end{bmatrix} \in \cp{M}_{2 \times 3}(\rac).
				            \]
				            Temos
				            \begin{align*}
					            \alpha\cdot(A + B) & = \alpha\cdot\left(
					            \begin{bmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{bmatrix} +
					            \begin{bmatrix} b_{11} & b_{12} & b_{13}\\b_{21} & b_{22} & b_{23}\end{bmatrix}\right)
					            \\ &= \alpha\cdot\left(\begin{bmatrix} a_{11} + b_{11} & a_{12} + b_{12} & a_{13} + b_{13}\\a_{21} + b_{21} & a_{22} + b_{22} & a_{23} + b_{23}\end{bmatrix}\right)
					            \\ &= \begin{bmatrix} \alpha(a_{11} + b_{11}) & \alpha(a_{12} + b_{12}) & \alpha(a_{13} + b_{13})\\\alpha(a_{21} + b_{21}) & \alpha(a_{22} + b_{22}) & \alpha(a_{23} + b_{23})\end{bmatrix}
					            \\ &= \begin{bmatrix} \alpha a_{11} + \alpha b_{11} & \alpha a_{12} + \alpha b_{12} & \alpha a_{13} + \alpha b_{13}\\\alpha a_{21} + \alpha b_{21} & \alpha a_{22} + \alpha b_{22} & \alpha a_{23} + \alpha b_{23}\end{bmatrix}
					            \\ &= \begin{bmatrix} \alpha a_{11} & \alpha a_{12} & \alpha a_{13} \\ \alpha a_{21} & \alpha a_{22} & \alpha a_{23} \end{bmatrix}
					            + \begin{bmatrix} \alpha b_{11} & \alpha b_{12} & \alpha b_{13}\\ \alpha b_{21} & \alpha b_{22} & \alpha b_{23} \end{bmatrix}
					            \\ &= \alpha\begin{bmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{bmatrix} +
					            \alpha\begin{bmatrix} b_{11} & b_{12} & b_{13}\\b_{21} & b_{22} & b_{23}\end{bmatrix}
					            \\ &= \alpha\cdot A + \alpha\cdot B
				            \end{align*}

				      \item[D2)] Sejam $\alpha$, $\beta \in \rac$ e
					      \[
						      A = \begin{bmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{bmatrix} \in \cp{M}_{2 \times 3}(\rac).
					      \]
					      Temos
					      \begin{align*}
						      (\alpha + \beta)\cdot A & = (\alpha + \beta)\cdot\begin{bmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{bmatrix}
						      \\ &= \begin{bmatrix} (\alpha + \beta)a_{11} & (\alpha + \beta)a_{12} & (\alpha + \beta)a_{13}\\(\alpha + \beta)a_{21} & (\alpha + \beta)a_{22} & (\alpha + \beta)a_{23}\end{bmatrix}
						      \\ &= \begin{bmatrix} \alpha a_{11} + \beta a_{11} & \alpha a_{12} + \beta a_{12} & \alpha a_{13} + \beta a_{13}\\\alpha a_{21} + \beta a_{21} & \alpha a_{22} + \beta a_{22} & \alpha a_{13} + \beta a_{23}\end{bmatrix}
						      \\ &= \begin{bmatrix} \alpha a_{11} & \alpha a_{12} & \alpha a_{13} \\ \alpha a_{21} & \alpha a_{22} & \alpha a_{13} \end{bmatrix}
						      + \begin{bmatrix} \beta a_{11} & \beta a_{12} & \beta a_{13} \\ \beta a_{21} & \beta a_{22} & \beta a_{13} \end{bmatrix}
						      \\ &= \alpha\cdot\begin{bmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{bmatrix}  + \beta\cdot\begin{bmatrix} a_{11} & a_{12} & a_{13}\\a_{21} & a_{22} & a_{23}\end{bmatrix}
						      \\ &= \alpha\cdot A + \beta\cdot A.
					      \end{align*}
			      \end{itemize}
			      Assim $V = \cp{M}_{2 \times 3}(\rac)$ é um espaço vetorial sobre $\rac$.
		      \end{solucao}

		\item De modo geral, o conjunto das matrizes $\cp{M}_{p \times q}(\cp{K})$ com coeficientes em $\cp{K}$ \'e um $\cp{K}$-espa\c{c}o vetorial com a soma usual de matrizes e a multiplica\c{c}\~ao por escalar usual.

		\item Considere o conjunto dos polin\^omios
		      \[
			      \mathcal{P}(\cp{K}) = \{ p(x) = a_nx^n + a_{n - 1}x^{n - 1} + \cdots + a_1x + a_0 \mid a_i \in \cp{K}, i = 0, 1, 2, \dots, n; n \ge 0 \}.
		      \]
		      Dados $p(x) = a_nx^n + a_{n - 1}x^{n - 1} + \cdots + a_1x + a_0$ e $q(x) = b_mx^m + b_{m - 1}x^{m - 1} + \cdots + b_1x + b_0$ em $\mathcal{P}(\cp{K})$, suponha que $n < m$ e defina:
		      \begin{itemize}
			      \item $(p + q)(x) = b_mx^m + b_{m - 1}x^{m - 1} + \cdots + b_{n + 1}x^{n + 1} + (a_n + b_n)x^n + \cdots + (a_1 + b_1)x + (a_0 + b_0)$
			      \item $(\alpha p)(x) = \alpha a_nx^n + \alpha a_{n - 1}x^{n - 1} + \cdots + \alpha a_1x + \alpha a_0$, onde $\alpha \in \cp{K}$.
		      \end{itemize}
		      Assim $\mathcal{P}(\cp{K})$ \'e um $\cp{K}$-espa\c{c}o vetorial.

		\item Seja $V = \{x \in \real \mid x > 0\} = \real_+^*$. Defina em $V$ as seguintes opera\c{c}\~oes:
		      \begin{align*}
			      x \oplus y        & = xy        \\
			      \lambda \otimes x & = x^\lambda
		      \end{align*}
		      para todos $x$, $y \in V$ e para todo $\lambda \in \real$. Ent\~ao com essas opera\c{c}\~oes $V$ \'e um $\real$-espa\c{c}o vetorial.
		      \begin{solucao}
			      Temos:
			      \begin{enumerate}
				      \item[A1)] $x \oplus y = xy = yx = y \oplus x$, para todos $x$, $y \in V$.
				      \item[A2)] $(x \oplus y) \oplus z = (xy) \oplus z = (xy)z = x(yz) = x \oplus (yz) = x \oplus (y \oplus z)$, para todos $x$, $y$, $z \in V$.
				      \item[A3)] Tome $0_V = 1$. Ent\~ao para todo $x \in V$ temos
					      \[
						      x\oplus 0_V = x\oplus 1 = x\cdot 1 = x.
					      \]
					      Logo $0_V = 1$ \'e o vetor nulo de $V$.
				      \item[A4)] Dado $x \in V$, tome $-x = \dfrac{1}{x} \in V$. Assim
					      \[
						      x \oplus (-x) = x \oplus \dfrac{1}{x} = x \cdot \dfrac{1}{x} = 1 = 0_V.
					      \]
				      \item[M1)] $(\alpha \beta)\otimes x = x^{\alpha \beta} = (x^\beta)^\alpha = \alpha \otimes (x^\beta) = \alpha \otimes (\beta \otimes x)$ para todos $\alpha$, $\beta \in \real$ e todo $x \in V$.
				      \item[M2)] $1_\real \otimes x = 1\otimes x = x^1 = x$ para todo $x \in V$.
				      \item[D1)] $\alpha \otimes (x \oplus y) = \alpha \otimes (xy) = (xy)^\alpha = (x^\alpha) (y^\alpha) = (\alpha \otimes x) (\alpha \otimes y) = (\alpha \otimes x) \oplus (\alpha \otimes y)$ para todos $x$, $y \in V$ e para todo $\alpha \in \real$.
				      \item[D2)] $(\alpha + \beta) \otimes x = x^{\alpha + \beta} = x^\alpha x^\beta = (\alpha \otimes x)(\beta \otimes x) = (\alpha \otimes x) \oplus (\beta \otimes x)$, para todos $\alpha$, $\beta \in \real$ e para todo $x \in V$.
			      \end{enumerate}
			      Portanto $V$ \'e um $\real$-espa\c{c}o vetorial.
		      \end{solucao}
	\end{enumerate}
\end{exemplo}

\begin{definicao}
	Seja $V$ um espa\c{c}o vetorial sobre $\cp{K}$. Um vetor $w \in V$ \'e uma \textbf{combina\c{c}\~ao linear}\index{Espaço Vetorial!combina\c{c}\~ao linear} dos vetores $u_1$, $u_2$, \dots, $u_n \in V$ se existirem escalares
	$\alpha_1$, $\alpha_2$, \dots, $\alpha_n \in \cp{K}$ tais que
	\[
		w = \alpha_1 u_1 + \alpha_2u_2 + \cdots + \alpha_nu_n = \sum_{i = 1}^n \alpha_iu_i.
	\]
\end{definicao}

\begin{exemplo}
	\begin{enumerate}[label={\arabic*})]
		\item O vetor $(1, 1, 1) \in \real^3$ \'e uma combina\c{c}\~ao linear dos vetores $u_1 = (1, 2, 3)$, $u_2 = (0, 1, 2)$ e $u_3 = (-1, 0, 1)$. De fato, precisamos encontrar $\alpha$, $\beta$ e $\gamma \in \real$ tais que:
		      \[
			      (1, 1, 1) = \alpha u_1 + \beta u_2 + \gamma u_3 = (\alpha - \gamma, 2\alpha + \beta, 3\alpha + 2\beta + \gamma).
		      \]
		      Assim resolvendo o sistema
		      \[
			      \begin{cases}
				      \alpha - \gamma = 1 \\
				      2\alpha + \beta = 1 \\
				      3\alpha + 2\beta + \gamma = 1
			      \end{cases}
		      \]
		      encontramos que suas solu\c{c}\~oes s\~ao dadas por
		      \begin{align*}
			      \alpha & = 1 + \gamma   \\
			      \beta  & = -1 - 2\gamma
		      \end{align*}
		      onde $\gamma \in \real$. Logo o vetor $(1, 1, 1)$ \'e de fato uma combina\c{c}\~ao linear dos vetores $u_1$, $u_2$ e $u_3$. Podemos tomar, por exemplo, $\gamma = 2$ e escrever
		      \[
			      (1, 1, 1) = 3(1, 2, 3) - 5(0, 1, 2) + 2(-1, 0 , 1).
		      \]

		\item O vetor $(1, -2, 2) \in \real^3$ n\~ao \'e uma combina\c{c}\~ao linear dos vetores $u_1 = (1, 2, 3)$, $u_2 = (0, 1, 2)$ e $u_3 = (-1, 0, 1)$. De fato, suponha que $\alpha$, $\beta$ e $\gamma \in \real$ s\~ao tais que:
		      \[
			      (1, -2, 2) = \alpha u_1 + \beta u_2 + \gamma u_3 = (\alpha - \gamma, 2\alpha + \beta, 3\alpha + 2\beta + \gamma).
		      \]
		      Assim resolvendo o sistema
		      \[
			      \begin{cases}
				      \alpha - \gamma = 1  \\
				      2\alpha + \beta = -2 \\
				      3\alpha + 2\beta + \gamma = 2
			      \end{cases}.
		      \]
		      A matriz escalonada reduzida por linha desse sistema \'e
		      \[
			      \begin{bmatrix}
				      1 & 0 & -1           & 0 \\
				      0 & 1 & \phantom{-}2 & 0 \\
				      0 & 0 & \phantom{-}0 & 1
			      \end{bmatrix}
		      \]
		      e portanto o sistema \'e imposs{\'\i}vel. Logo o vetor $(1, -2, 2)$ n\~ao \'e uma combina\c{c}\~ao linear dos vetores $u_1$, $u_2$ e $u_3$.

		\item Considere o $\real$-espa\c{c}o vetorial $\real^3$. Dado um vetor $(a, b, c) \in \real^3$ podemos escrever
		      \[
			      (a, b, c) = a(1, 0, 0) + b(0, 1, 0) + c(0, 0, 1).
		      \]
		      Assim qualquer vetor de $\real^3$ \'e uma combina\c{c}\~ao linear dos vetores $(1, 0 , 0)$, $(0, 1 , 0)$ e $(0, 0 , 1)$.

		\item Qualquer vetor de $\real^3$ pode ser escrito como uma combinação linear dos vetores no conjunto: $\mathcal{B} = \{(1, 0 , 1), (1, 1 , 0), (1, 1 , 1), (-1, 0, 0), (-1, -1, 0), (-1, -1, -1)\}$.
		      \begin{solucao}
			      De fato, dado $(a, b, c) \in \real^3$, queremos encontrar $x_1$, $x_2$, $x_3$, $x_4$, $x_5$, $x_6 \in \real$ tais que
			      \[
				      (a, b, c) = x_1(1, 0 , 1) + x_2(1, 1 , 0) + x_3(1, 1 , 1) + x_4(-1, 0, 0) + x_5(-1, -1, 0) + x_6(-1, -1, -1).
			      \]
			      O que fornece o sistema
			      \[
				      \begin{cases}
					      x_1 + x_2 + x_3 - x_4 - x_5 - x_6 = a \\
					      x_2 + x_3 - x_5 - x_6 = b             \\
					      x_1 + x_3 - x_6 = c
				      \end{cases}
			      \]
			      cuja matriz escalonada reduzida por linhas \'e
			      \[
				      \begin{amatrix}{6}
					      1 & 0 & 0 & -1 & \phantom{-}0 & \phantom{-}0 & a - b\\
					      0 & 1 & 0 & -1 & -1 & \phantom{-}0 & a - c\\
					      0 & 0 & 1 & \phantom{-}1 & \phantom{-}0 & -1 & b + c - a
				      \end{amatrix},
			      \]
			      assim o sistema \'e poss{\'\i}vel e indeterminado, com posto 3 e nulidade 3. Sua solu\c{c}\~ao \'e descrita pela equa\c{c}\~oes
			      \begin{align*}
				      x_1 & = a - b + x_4           \\
				      x_2 & = a - c + x_4 + x_5     \\
				      x_3 & = b + c - a - x_4 + x_6
			      \end{align*}
			      onde $x_4$, $x_5$ e $x_6 \in \real$. Portanto qualquer vetor de $\real^3$ pode ser escrito como uma combinação linear dos elementos do conjunto $\mathcal{B}$.
		      \end{solucao}

		    \item O vetor
		    	\[
		    		w = \begin{bmatrix}
		    			1 & 0\\
		    			0 & 1
		    		\end{bmatrix}
		    	\]
		    	é uma combinação linear dos vetores
		    	\[
		    		u_1 = \begin{bmatrix}3 & \phantom{-}6\\3 & -6\end{bmatrix},
		    		u_2 = \begin{bmatrix}\phantom{-}0 & -1\\-1 & \phantom{-}0\end{bmatrix},
		    		u_3 = \begin{bmatrix}\phantom{-}0 & -8\\-12 & -4\end{bmatrix},
		    		u_4 = \begin{bmatrix}\phantom{-}1 & 0\\-1 & 2\end{bmatrix}.
		    	\]
		    	\begin{solucao}
		    		De fato, precisamos encontrar escalares $\alpha_1$, $\alpha_2$, $\alpha_3$, $\alpha_4 \in \rac$ tais que
		    		\[ w = \alpha_1 u_1 + \alpha_2 w_2 + \alpha_3 u_3 + \alpha_4 u_4.\]
		    		Com isso obtemos o sistema linear
		    		\[
		    			\begin{cases}
		    				3\alpha_1 + \alpha_4 = 1\\
		    				6\alpha_1 - \alpha_2 - 8\alpha_3 = 0\\
		    				3\alpha_1 - \alpha_2 - 12 \alpha_3 - \alpha_4 = 0\\
		    				-6\alpha_1 - 4\alpha_3 + 2\alpha_4 = 1
		    			\end{cases}
		    		\]
		    		cuja matriz escalonada reduzida por linhas é
		    		\[
		    			\begin{amatrix}{4}
		    				1 & 0 & 0 & 1/3 & 1/3\\
		    				0 & 1 & 8 & 2 & 2\\
		    				0 & 0 & 1 & 0 & -1/4\\
		    				0 & 0 & 0 & 1 & 1/2
		    			\end{amatrix}.
		    		\]
		    		Assim
		    		\[\alpha_1 = 1/6, \alpha_2 = 3, \alpha_3 = -1/4, \alpha_4 = 1/2.\]
		    	\end{solucao}
	\end{enumerate}
\end{exemplo}

\begin{definicao}
	Seja $V$ um $\cp{K}$-espa\c{c}o vetorial. Um subconjunto n\~ao vazio $W$ de $V$ \'e um \textbf{subespa\c{c}o vetorial}\index{Espaço Vetorial!subespaço} de $V$ se $W$ é um espaço vetorial
	sobre $\cp{K}$ com respeito às mesmas operações definidas em $V$.
\end{definicao}

\begin{exemplo}
	\begin{enumerate}[label={\arabic*})]
		\item O subconjunto $W = \{0_V\}$ \'e um subespa\c{c}o vetorial de qualquer espa\c{c}o vetorial $V$. O pr\'oprio $V$ como subconjunto de $V$ \'e tamb\'em um subespa\c{c}o vetorial. Estes dois subespa\c{c}os s\~ao chamados de \textbf{subespa\c{c}os triviais}.
		\item Seja $V$ um $\cp{K}$-espa\c{c}o vetorial e $w \in V$. Ent\~ao o conjunto $\cp{K}w = \{\alpha w \mid \alpha \in \cp{K}\}$ \'e um subespa\c{c}o vetorial de $V$.
	\end{enumerate}
\end{exemplo}

\begin{teorema}\label{teoremasubespaco}
	Um subconjunto n\~ao vazio $W$ de um $\cp{K}$-espa\c{c}o vetorial $V$ \'e um subespa\c{c}o de $V$ se, e somente se:
	\begin{enumerate}[label={\roman*})]
		\item para todos vetores $u_1$, $u_2 \in W$ temos $u_1 + u_2 \in W$.
		\item para todo escalar $\lambda \in \cp{K}$ e todo vetor $u \in W$, temos $\lambda u\in W$.
	\end{enumerate}
\end{teorema}

\begin{exemplos}
	\begin{enumerate}[label={\arabic*})]
		\item Considere o seguinte sistema linear homogêneo:
			\begin{align}\label{exemplosistemahomogeneosubespaco}
				\begin{cases}
					2x_1 + 4x_2 + 6x_3 = 0\\
					3x_1 - 2x_2 - 4x_3 = 0\\
					x_1 + 2x_2 + 3x_3 = 0
				\end{cases}
			\end{align}
			cuja solução é dada pelo conjunto:
			\[
				S = \{(t/4,13t/8,t) \mid t \in \real\}.
			\]
			Observer que $S \subseteq \real^3$. Agora $\real^3$ é um espaço vetorial sobre $\real$, como isso temos a seguinte pergunta: $S$ é um subespaço vetorial de $\real^3$?
			\begin{solucao}
				Primeiro observe que $S \ne \emptyset$ pois $(0,0,0) \in S$ e é uma solução para o sistema linear homogêneo. Assim podemos aplicar o Teorema \ref{teoremasubespaco}. Para isso sejam $u_1$, $u_2 \in S$ e $\lambda \in \real$.
				Precisamos mostrar que $u_1 + u_2 \in S$ e que $\lambda u_1 \in S$. Mas como $u_1$, $u_2 \in S$ então
				\[
					u_1 = (t/4, -13t/8, t),
					u_2 = (r/4, -13r/8,r)
				\]
				onde $t$, $r \in \real$. Assim
				\[
					u_1 + u_2 = ((t + r)/4, -13(t + r)/8, t + r).
				\]
				e com isso o vetor $u_1 + u_2$ está no formato de um elemento de $S$, logo $u_1 + u_2 \in S$.

                Agora,
                \[
                    \lambda u_1 = (\lambda t/4, -13\lambda t/4, \lambda t)
                \]
			    e novamente o vetor $\lambda u_1$ está no formado de um elemento de $S$, logo $\lambda u_1 \in S$.

                Portanto, pelo Teorema \ref{teoremasubespaco} $S$ é um subespaço vetorial de $\real^3$.
		  \end{solucao}
	\item Considere $V = \real^5$ um espaço vetorial sobre $\real$. Tome o subconnjunto $W = \{(0,x_2,x_3,x_4,x_5) \in \real^5 \mid x_i \in \real, 1 \le i \le 5\}$. Então $W$ \'e um subespa\c{c}o de $V$.
		\begin{solucao}
			Como $x_2$, $x_3$, $x_4$ e $x_5$ são números reais quaisquer podemos tomar $x_2 = x_3 = x_4 = x_ 5 = 0$. Assim $(0, 0, 0, 0, 0) \in W$ e com isso $W \ne \emptyset$. Agora sejam $w_1$, $w_2 \in W$. Com isso
			\begin{align*}
				w_1 &= (0,x_2, x_3, x_4, x_5)\\
				w_2 &= (0,y_2, y_3, y_4, y_5)
			\end{align*}
			onde $x_i$, $y_i \in \real$ para $1 \le i \le 5$. Assim
			\[
				w_1 + w_2 = (0,x_2, x_3, x_4, x_5) + (0,y_2, y_3, y_4, y_5) = (0, x_2 + y_2, x_3 + y_3, x_4 + y_4, x_5 + y_5)
			\]
			e então $w_1 + w_2 \in W$.

			Agora tome $\lambda \in \real$ e $w = (0, x_2, x_3, x_4, x_5) \in W$. Então
			\[
				\lambda w = \lambda(0, x_2, x_3, x_4, x_5) = (0, \lambda x_2, \lambda x_3, \lambda x_4, \lambda x_5)
			\]
			e então $\lambda w \in W$.

			Portanto, pelo Teorema \ref{teoremasubespaco}, $W$ é um subespaço vetorial de $\real^5$.
		\end{solucao}

	\item Considere $V = M_n(\cp{K})$ um espaço vetorial sobre $\cp{K}$. Seja
		\[
			W = UT_n(\cp{K}) = \left\{
				\begin{bmatrix}
				      a_{11}   & a_{12}   & \cdots & a_{1n} \\
				      0_\cp{K} & a_{22}   & \cdots & a_{2n} \\
				      \vdots                                \\
				      0_\cp{K} & 0_\cp{K} & \cdots & a_{nn}
			      \end{bmatrix}
			    \mid a_{ij} \in \cp{K}
			  \right\}.
			\]
			Então $W = UT_n(\cp{K})$ \'e um subespa\c{c}o de $V$.
			\begin{solucao}
				Exercício!
			\end{solucao}

		\item Considere $V = \complex^2$ um espaço vetorial sobre $\complex$. Tome $W = \{(x, x^2) \mid x \in \complex\}$. Então $W$ n\~ao \'e subespa\c{c}o de $V$
			\begin{solucao}
				De fato, primeiro observe que $(0,0) \in W$ e então $W \ne \emptyset$. Com isso podemos aplicar o Teorema \ref{teoremasubespaco}. Tome, por exemplo, $u = (1,1)$, $v = (2,4)$. Observe que $u_1$, $u_2 \in W$ e no entanto $u + v  = (3, 5) \notin W$.
				Portanto $W$ não é um subespaço vetorial de $V$.
			\end{solucao}

		\item Considere $V = M_2(\real)$ um $\real$-espaço vetorial. Tome
			\[
				T = \left\{
					\begin{bmatrix}
						a & b\\
						c & d
					\end{bmatrix}
					\mid a, b, c, d \in \real \mbox{ e pelo menos uma entrada nula}
				\right\}.
			\]
			Então $T$ não é um subespaço vetorial de $V$.
			\begin{solucao}
				De fato, observe que
				\[
					\begin{bmatrix}
						0 & 0\\
						0 & 0
					\end{bmatrix} \in T
				\]
				e então $T \ne \emptyset$. Logo podemos aplicar o Teorema \ref{teoremasubespaco}. Sejam
				\begin{align*}
					A &= \begin{bmatrix}1 & 2\\3 & 0\end{bmatrix} \in T,\\
					B &= \begin{bmatrix}2 & 0\\1 & 1\end{bmatrix} \in T,
				\end{align*}
				e no entanto
				\[
					A + B = \begin{bmatrix}1 & 2\\3 & 0\end{bmatrix} +
					\begin{bmatrix}2 & 0\\1 & 1\end{bmatrix} =
					\begin{bmatrix}3 & 2\\4 & 1 \end{bmatrix}\notin T.
				\]
				Portanto $T$ não é um subespaço vetorial de $V$.
			\end{solucao}
	\end{enumerate}
\end{exemplos}


\begin{definicao}
	Seja $V$ um $\cp{K}$-espaço vetorial. Fixado vetores $v_1$, $v_2$, \dots, $v_n \in V$ o conjunto
	\[
	W = \{\alpha_1v_1 + \alpha_2v_2 + \cdots + \alpha_nv_n \mid \alpha_i \in \cp{K}\}
	\]
	é chamado de \textbf{espaço gerado}\index{Espaço vetorial!espaço gerado} por $\{v_1, v_2, \dots, v_n\}$ e os vetores $\{v_1, v_2, \dots, v_n\}$ são chamados de \textbf{geradores}\index{Espaço vetorial!geradores} de $W$.
\end{definicao}

\begin{notacao}
	O espaço gerado $W = \{\alpha_1v_1 + \alpha_2v_2 + \cdots + \alpha_nv_n\}$ pode ser escrito como $W = Span(v_1, v_2, \dots, v_n)$ ou $W = <v_1, v_2, \dots, v_n>$ ou ainda como $W = [v_1, v_2, \dots, v_n]$.
\end{notacao}

\begin{proposicao}
	Seja $V$ um $\cp{K}$-espaço vetorial. Fixado vetores $v_1$, $v_2$, \dots, $v_n \in V$ o conjunto
	\[
		W = \{\alpha_1v_1 + \alpha_2v_2 + \cdots + \alpha_nv_n \mid \alpha_i \in \cp{K}\}
	\]
	é um subespaço vetorial de $V$.
\end{proposicao}

\begin{exemplos}\label{exemplosespacosgerados}
    \begin{enumerate}
        \item\label{exemplor2} Seja $V = \real^2$ um espaço vetorial sobre $\real$. Tome os vetores $e_1 = (1,0)$ e $e_2 = (0, 1)$. Temos
        \begin{align*}
            W &= Span(e_1, e_2) = \{ae_1 + be_2 \mid a, b \in \real\} = \{a(1, 0) + b(0, 1) \mid a, b \in \real\} \\ &= \{(a, 0) + (0, b) \mid a, b \in \real\} = \{(a, b) \mid a, b \in \real\} = \real^2.
        \end{align*}

        \item\label{exemplor3} Considere agora $V = \real^3 = \{(x , y, z) \mid x, y, z \in \real\}$ um $\real$-espaço vetorial. Dados os vetores $e_1 = (1,0, 0)$, $e_2 = (0, 1, 0)$ e $e_3 = (0, 0, 1)$ então
        \begin{align*}
            W &= Span(e_1, e_2, e_3) = \{ae_1 + be_2 + ce_3 \mid a, b, c \in \real\} \\ &= \{a(1, 0, 0) + b(0, 1, 0) + c(0, 0, 1) \mid a, b, c \in \real\} \\ &= \{(a, 0, 0) + (0, b, 0) + (0, 0, c) \mid a, b, c \in \real\} \\ &= \{(a, b, c) \mid a, b, c \in \real\} = \real^3.
        \end{align*}

        \item\label{exemplokn} De modo geral, para $V = \cp{K}^n$ um espaço vetorial sobre o corpo $\cp{K}$ tomando
        \begin{align*}
            e_1 &= (1, 0, 0, 0, \dots, 0 , 0)\\
            e_2 &= (0, 1, 0, 0, \dots, 0 , 0)\\
            e_3 &= (0, 0, 1, 0, \dots, 0 , 0)\\
            \vdots\\
            e_n &= (0, 0, 0, 0, \dots, 0 , 1)\\
        \end{align*}
        então teremos
        \begin{align*}
            W &= Span(e_1, e_2, e_3, \dots, e_n) \\ &= \{\alpha_1e_1 + \alpha_2e_2 + \alpha_3e_3 + \cdots + \alpha_ne_n \mid \alpha_1, \alpha_2, \alpha_3, \dots, \alpha_n \in \cp{K}\} \\ &= \cp{K}^n
        \end{align*}

        \item Sem $V = M_2(\real)$ um $\real$-espaço vetorial. Considere os vetores
        \[
            u = \begin{pmatrix}
                -1 & 2\\-2 & 3
            \end{pmatrix},
            w = \begin{pmatrix}
                3 & -1\\1 & \phantom{-}1
            \end{pmatrix}.
        \]
        Encontre $W = Span(u, w)$.
        \begin{solucao}
            Por definição
            \begin{align*}
                W &= Span(u, w) = \{\alpha u + \beta w \mid \alpha, \beta \in \real\} \\ &= \left\{\alpha\begin{pmatrix}-1 & 2\\-2 & 3\end{pmatrix} + \beta \begin{pmatrix}3 & -1\\1 & \phantom{-}1\end{pmatrix} \mid \alpha, \beta \in \real\right\} \\ &= \left\{\begin{pmatrix}-\alpha & 2\alpha\\-2\alpha & 3\alpha\end{pmatrix} + \begin{pmatrix}3\beta & -\beta\\\beta & \beta\end{pmatrix} \mid \alpha, \beta \in \real\right\} \\ &= \left\{\begin{pmatrix}-\alpha + 3\beta & 2\alpha - \beta\\-2\alpha + \beta & 3\alpha + \beta\end{pmatrix} \mid \alpha, \beta \in \real\right\}.
            \end{align*}
            Agora dada uma matriz $A \in V$, quando $A \in W$? Para determinar isso seja
            \[
                A = \begin{bmatrix}
                    x & y\\
                    z & t
                \end{bmatrix}.
            \]
            Para que $A \in W$ devemos ter
            \[
            A = \begin{bmatrix}
                x & y\\
                z & t
            \end{bmatrix} = \begin{pmatrix}-\alpha + 3\beta & 2\alpha - \beta\\-2\alpha + \beta & 3\alpha + \beta\end{pmatrix}
            \]
            para algum $\alpha$, $\beta \in \real$. Com isso obtemos o sistema linear
            \[
                \begin{cases}
                    -\alpha + 3\beta = x\\
                    2\alpha - \beta = y\\
                    -2\alpha + \beta = z\\
                    3\alpha + \beta = t
                \end{cases}
            \]
            Montando a matriz ampliada e aplicando a eliminação guassiana:
            \begin{align*}
                \begin{amatrix}{2}
                    -1 & 3 & x\\
                    2 & -1 & y\\
                    -2 & 1 & z\\
                    3 & 1 & t
                \end{amatrix}
                \begin{array}{l}
                    L_1 \to -L_1\\\phantom{x}\\\phantom{x}\\\phantom{x}
                \end{array}&\sim
                \begin{amatrix}{2}
                    1 & -3 & -x\\
                    2 & -1 & y\\
                    -2 & 1 & z\\
                    3 & 1 & t
                \end{amatrix}
                \begin{array}{l}
                    \phantom{x}\\L_2 \to L_2 - 2L_1\\L_3 \to L_3 + 2L_1\\L_4 \to L_4 - 3L_1
                \end{array}\\&\sim
                \begin{amatrix}{2}
                    1 & -3 & -x\\
                    0 & 5 & y + 2x\\
                    0 & -5 & z - 2x\\
                    0 & 10 & t + 3x
                \end{amatrix}
                \begin{array}{l}
                    \phantom{x}\\\phantom{x}\\L_3 \to L_3 + L_2\\L_4 \to L_4 - 2L_1
                \end{array}\\ &\sim
                \begin{amatrix}{2}
                    1 & -3 & -x\\
                    0 & 5 & y + 2x\\
                    0 & 0 & z + y\\
                    0 & 0 & t - x - 2y
                \end{amatrix}
                \begin{array}{l}
                    \phantom{x}\\L_2 \to \dfrac{1}{5}L_2\\\phantom{x}\\\phantom{x}
                \end{array}\\ &\sim
                \begin{amatrix}{2}
                    1 & -3 & -x\\
                    0 & 1 & (y + 2x)/5\\
                    0 & 0 & z + y\\
                    0 & 0 & t - x - 2y
                \end{amatrix}
            \end{align*}
            Para que esse sistema seja possível, devemos ter
            \[
                \begin{cases}
                    y + z = 0\\
                    t - x - 2y =0
                \end{cases}
            \]
            ou seja, $y = -z$ e $x = t + 2z$. Portanto
            \[
                W = Span(u, w) = \left\{\begin{bmatrix}x & y\\z & t\end{bmatrix} \mid x = t + 2z, y = -z, t, z \in \real\right\} = \left\{\begin{bmatrix}t + 2z & -z\\z & t\end{bmatrix} \mid t, z \in \real\right\}.
            \]
            Assim atribuindo valores para $z$ e $t$ encontramos elementos do subespaço $W$. Por exemplo, fazendo $z = -1$ e $t = 1$ temos
            \[
                \begin{bmatrix}-1 & 1\\-1 & 1 \end{bmatrix} \in W = Span(u, w).
            \]
            Agora observer que a matrix
            \[
                \begin{bmatrix}
                    4 & -3\\
                    3 & -2
                \end{bmatrix}
            \]
            pertence ao subespaço $W = Span(u, w)$. Vamos então encontrar escalares $\alpha$, $\beta$ de modo que essa matriz seja uma combinação linear de $u$ e $w$. Para fazer isso, basta usar a matriz obtida na eliminação gaussiana:
            \[
                \begin{amatrix}{2}
                    1 & -3 & -x\\
                    0 & 1 & (y + 2x)/5\\
                    0 & 0 & z + y\\
                    0 & 0 & t - x - 2y
                \end{amatrix}.
            \]
            A partir dessa matriz temos
            \[
                \begin{cases}
                    \alpha = -x + 3\beta\\
                    \beta = \dfrac{y + 2x}{5}
                \end{cases}
            \]
            com isso, $\alpha = -7$ e $\beta = -1$.
        \end{solucao}

    \end{enumerate}
\end{exemplos}

\begin{definicao}
    Um espaço vetorial $V$ é chamado de \textbf{finitamente gerado}\index{Espaço vetorial!finitamente gerado} se existe um conjunto finito de vetores $\{v_1, v_2, \dots, v_n\}$ em $V$ tais que
    \[
        V = Span(v_1, v_2, \dots, v_n).
    \]
\end{definicao}


\begin{exemplos}
    \begin{enumerate}
        \item Conforme visto nos Exemplos \ref{exemplosespacosgerados}, itens \ref{exemplor2}, \ref{exemplor3} e \ref{exemplokn}, os espaços vetorias $\real^2$, $\real^3$ e $\cp{K}^n$ são todos espaços finitamente gerados.

        \item Considere $M_2(\complex)$ um $\complex$-espaço vetorial. Dadas as matrizes
        \begin{align*}
            E_{11} &= \begin{bmatrix}1 & 0\\0 & 1\end{bmatrix},
            E_{12} = \begin{bmatrix}0 & 1\\0 &0 \end{bmatrix},\\
            E_{21} &= \begin{bmatrix}1 & 0\\0 & 0\end{bmatrix},
            E_{22} = \begin{bmatrix}0 & 1\\0 & 0\end{bmatrix}.
        \end{align*}
        Então
        \[
            M_2(\complex) = Span(E_{11}, E_{12}, E_{12}, E_{22}),
        \]
        ou seja, $M_2(\complex)$ é um espaço vetorial finitamente gerado.

        \item Agora tome $V = M_2(\complex)$ como um espaço vetorial sobre $\real$. Então as matrizes do exemplo anterior não geram o espaço vetorial $V$. Para ver isso, tome
        \[
            \begin{bmatrix}
                i & 0\\0 & 0
            \end{bmatrix} \in M_2(\complex).
        \]
        Não existem escalares $\alpha_1$, $\alpha_2$, $\alpha_3$, $\alpha_4 \in \real$ tais que
        \[
            \alpha_1E_{11} + \alpha_2E_{12} + \alpha_3E_{21} + \alpha_4E_{22} = \begin{bmatrix}i & 0\\0 & 0\end{bmatrix}.
        \]
        Mas se consideramos as matrizes
        \begin{align*}
            E_{11} &= \begin{bmatrix}1 & 0\\0 & 1\end{bmatrix},
            E_{12} = \begin{bmatrix}0 & 1\\0 &0 \end{bmatrix},\\
            E_{21} &= \begin{bmatrix}1 & 0\\0 & 0\end{bmatrix},
            E_{22} = \begin{bmatrix}0 & 1\\0 & 0\end{bmatrix},\\
            F_{11} &= \begin{bmatrix}i & 0\\0 & 1\end{bmatrix},
            F_{12} = \begin{bmatrix}0 & i\\0 &0 \end{bmatrix},\\
            F_{21} &= \begin{bmatrix}i & 0\\0 & 0\end{bmatrix},
            F_{22} = \begin{bmatrix}0 & i\\0 & 0\end{bmatrix}.
        \end{align*}
        Então $M_2(\complex)$ é um espaço vetorial sobre $\real$ finitamente gerado e
        \[
            M_2(\complex) = Span(E_{11}, E_{12}, E_{12}, F_{22}, F_{11}, F_{12}, F_{12}, F_{22}).
        \]

        \item No caso geral, considere $V = M_{p \times q}(\cp{K})$ um $\cp{K}$-espaço vetorial. Tome as matrizes
         \[
            E_{ij} = \begin{cases}
                a_{ij} = 1\\
                0, \mbox{ caso contrário}
                \end{cases}.
         \]
         Então
         \[
            M_{p \times q}(\cp{K}) = Span(E_{11}, E_{12}, \dots, E_{1q}, E_{21}, E_{22}, \dots, E_{2q}, \dots, E_{p1}, E_{pq}, \dots, E_{pq}).
         \]
    \end{enumerate}
\end{exemplos}

\begin{definicao}
	Dados dois subespaços vetoriais $W_1$ e $W_2$ de um $\cp{K}$-espaço vetorial $V$, definimos a interseção de $W_1$ e $W_2$ como o subconjunto
	\[
		W_1 \cap W_2 = \{u \in V \mid u\in W_1 \mbox{ e } u \in W_2\}.\
	\]
\end{definicao}


\begin{teorema}
	Dados $W_1$, $W_2$ dois subespaços de um $\cp{K}$-espaço vetorial $V$, então $W_1 \cap W_2$ também é um subespaço vetorial de $V$.
\end{teorema}

\begin{observacao}
	Se $W_1$ e $W_2$ são subespaços de $V$, então nem sempre o conjunto $W_1 \cup W_2 = \{u \in V \mid u \in W_1 \mbox{ ou } u \in W_2\}$ é um subespaço de $V$.
\end{observacao}

\begin{exemplo}
	No $\real$-espaço vetorial $\real^2$ sejam $W_1 = Span((1,0))$ e $W_2 = Span((0, 1))$ subespaços. Então
	\[
		W_1 \cup W_2 = \{(x, y) \in \real^2 \mid (x, y) \in W_1 \mbox{ ou } (x, y) \in W_2\} = \{(\alpha, 0); (0, \beta) \mid \alpha, \beta \in \real\}.
	\]
	Observer que $u_1 = (1, 0) \in W_1$, $u_2 = (0, 1) \in W_2$ e no entanto $u_1 + u_2 = (1, 1) \notin W_1 \cup W_2$. Assim $W_1 \cup W_2$ não é um subespaço vetorial de $\real^2$.
\end{exemplo}

\begin{definicao}
	Dados dois subespaços $U$ e $W$ de um $\cp{K}$-espaço vetorial $V$, definimos a \textbf{soma de $U$ e $W$}\index{Espaço vetorial!soma} como o subconjunto
	\[
		U + W = \{u + w \mid u \in U, w \in W\}.
	\]
\end{definicao}

\begin{teorema}
	Dados dois subespaços $U$ e $W$ de um $\cp{K}$-espaço vetorial $V$, então $U + W$ é um subespaço de $V$.
\end{teorema}

De acordo com o Exemplo \ref{exemplosespacosgerados}, item \ref{exemplor2}, podemos escrever
\[
	\real^2 = Span(e_1, e_2)
\]
onde $e_1 = (1, 0)$ e $e_2 = (0, 1)$. Assim dado $(x, y) \in \real^2$ temos
\[
	(x, y) = ae_1 + be_2 = a(1, 0) + b(0, 1) = (a, 0) + (0, b) = (a, b)
\]
daí vemos que existe um único valor de $a$ e um único valor de $b$ que tornam o vetor $(x, y)$ uma combinação linear de $e_1$ e $e_2$. Tais escalares são dados por $a = x$ e $b = y$.

Por outro lado, se tomamos $v_1 = (1, 2)$ e $v_2 = (1, 3)$ então dado $(x, y) \in \real^2$, existem escalares $a$, $b \in \real$ tais que
\[
	(x, y) = av_1 + bv_2?
\]
Primeiro podemos escrever
\[
	(x, y) = a(1, 2) + b(1, 3) = (a + b, 2a + 3b),
\]
com isso obtemos o sistema linear
\[
	\begin{cases}
		a + b = x\\
		2a + 3b = y
	\end{cases}.
\]
Aplicando o método de eliminação guassiana:
\begin{align*}
	\begin{amatrix}{2}
		1 & 1 & x\\
		2 & 3 & y
	\end{amatrix}
	\begin{array}{l}
		\phantom{x}\\L_2 \to L_2 - 2L_1
	\end{array}\sim
	\begin{amatrix}{2}
		1 & 1 & x\\
		0 & 1 & y - 2x
	\end{amatrix}
	\begin{array}{l}
		L_1 \to L_1 - L_2\\\phantom{x}
	\end{array}\sim
	\begin{amatrix}{2}
		1 & 0 & 3x - y\\
		0 & 1 & y - 2x
	\end{amatrix}
\end{align*}
Logo existem únicos $a$ e $b$ que tornam $(x, y)$ uma combinação linear de $v_1$ e $v_2$. Seus valores são dados por:
\[
	a = 3x - y,\ b = y - 2x.
\]
Nesse caso também temos
\[
	\real^2 = Span(v_1, v_2).
\]

Agora, tomando $v_1 = (1, 2)$, $v_2 = (1, 3)$ e $v_3 = (1, 5)$ também temos
\[
	\real^2 = [v_1, v_2, v_n] = \{\alpha_1v_1 + \alpha_2v_2 + \alpha_3v_3 \mid \alpha_1, \alpha_2, \alpha_3 \in \real\}.
\]
De fato, como $\real^2 = [v_1, v_2]$ então todo vetor $w \in \real^2$ pode ser escrito como
\[
	w = av_1 + bv_2
\]
para certos escalares $a$, $b \in \real$. Assim podemos escrever também
\[
	w = av_1 + bv_2 + 0v_3
\]
e com isso $w \in [v_1, v_2, v_3]$. Logo $[v_1, v_2] \subset [v_1, v_2, v_3]$.

Por outro lado, tomando $u \in [v_1, v_2, v_3]$ então existem escalares $\alpha_1$, $\alpha_2$, $\alpha_3 \in \real$ tais que
\[
	u = \alpha_1v_1 + \alpha_2v_2 + \alpha_3v_3.
\]
Mas, observe que $v_3 = -2v_1 + 3v_2$, daí
\begin{align*}
	u = \alpha_1v_1 + \alpha_2v_2 + \alpha_3v_3 \\ &= \alpha_1v_1 + \alpha_2v_2 + \alpha_3(-2v_1 + 3v_2) \\&=
	\alpha_1v_1 + \alpha_2v_2 -2\alpha_3v_1 + 3\alpha_3v_2 \\ &= (\alpha_1 - 2\alpha_3)v_1 + (\alpha_2 + 3\alpha_3)v_2
\end{align*}
e com isso, $u \in [v_1, v_2]$. Ou seja, $[v_1, v_2, v_3] \subset [v_1, v_2]$.

Portanto,
\[
	[v_1, v_2] = [v_1, v_2, v_3]
\]
ou seja
\[
	\real^2 = [v_1, v_2] = [v_1, v_2, v_3].
\]

Qual é a diferença entre escrever $\real^2 = [v_1, v_2]$ e $\real^2 = [v_1, v_2, v_3]$?

Seja $w = (x, y) \in \real^2$. Quando escrevemos $\real^2 = [v_1, v_2]$ os escalares $a$, $b \in \real$ que aparecem na combinação linear
\[
	w = av_1 + bv_2
\]
são únicos e dados por
\[
	a = 3x - y,\ b = y - 2x.
\]

Agora, quando escrevemos $\real^2 = [v_1, v_2, v_3]$, existem escalares $a$, $b$ e $c \in \real$ tais que
\begin{align*}
	w &= \alpha_1v_1 + \alpha_2v_2 + \alpha_3v_3\\
	(x, y) &= \alpha_1(1, 2) + \alpha_2(1, 3) + \alpha_3(1, 5)
\end{align*}
que resulta no sistema linear
\[
	\begin{cases}
		\alpha_1 + \alpha_2 + \alpha_3 = x\\
		2\alpha_1 + 3\alpha_2 + 5\alpha_3 = y
	\end{cases}
\]
que escalonando:
\begin{align*}
	\begin{amatrix}{3}
		1 & 1 & 1 & x\\
		2 & 3 & 5 & y
	\end{amatrix}
	\begin{array}{l}
		\phantom{x}\\L_2 \to L_2 - 2L_1
	\end{array}\sim
	\begin{amatrix}{3}
		1 & 1 & 1 & x\\
		0 & 1 & 3 & y - 2x
	\end{amatrix}
	\begin{array}{l}
		L_1 \to L_1 - L_2\\\phantom{x}
	\end{array}\sim
	\begin{amatrix}{3}
		1 & 0 & -2 & 3x - y\\
		0 & 1 & 3 & y - 2x
	\end{amatrix}
\end{align*}

A solução desse sistema é dada por
\begin{align*}
	\alpha_1 &= (3x - y) + 2\alpha_3\\
	\alpha_2 &= (y - 2x) - 3\alpha_3
\end{align*}
onde $alpha_3 \in \real$. Logo existem infinitas formas de escrever um mesmo vetor $w = (x, y)$ como
combinação linear de $v_1$, $v_2$ e $v_3$. Por exemplo, para o vetor nulo $(0, 0)$ obtemos
\begin{align*}
	(0, 0) &= 0v_1 + 0v_2 + 0v_3\\
	(0, 0) &= 2v_1 - 3v_2 + v_3\\
	(0, 0) &= 2\sqrt{2}v_1 - 3\sqrt{2}v_2 + \sqrt{2}v_3\\
				 &\vdots
\end{align*}

Esse caso motiva a seguinte definição:
\begin{definicao}
  Seja $V$ um $\cp{K}$-espaço vetorial. Dados vetores $v_1$, $v_2$, \dots, $v_n$ em $V$ dizemos que:
  \begin{enumerate}[label={\roman*})]
    \item o conjunto $\{v_1, v_2, \dots, v_n\}$ é \textbf{linearmente dependentes} ou que os vetores $v_1$, $v_2$, \dots, $v_n$ são \textbf{linearmente dependentes}, 
    	abreviado como L.D, se existem escalares
      $\alpha_1$, $\alpha_2$, \dots, $\alpha_n \in \cp{K}$, \textbf{não todos nulos}, tais que
      \[
        \alpha_1v_1 + \alpha_2v_2 + \cdots + \alpha_nv_n = 0_V.
      \]

    \item o conjunto $\{v_1, v_2, \dots, v_n\}$ é \textbf{linearmente independentes} ou que os vetores $v_1$, $v_2$, \dots, $v_n$ 
    	são \textbf{linearmente independentes}, abreviado como L.I, se dados escalares
      $\alpha_1$, $\alpha_2$, \dots, $\alpha_n \in \cp{K}$  tais que
      \[
        \alpha_1v_1 + \alpha_2v_2 + \cdots + \alpha_nv_n = 0_V,
      \]
      então $\alpha_1 = \alpha_2 = \cdots = \alpha_n = 0$.
  \end{enumerate}
\end{definicao}

\begin{exemplos}
	\begin{enumerate}
		\item Considere o $\real$-espaço vetorial $\real^2$. O conjunto $\{(1, 0); (0, 1)\}$ é linearmente independente, pois se $a$, $b \in \real$ são tais que
			\[
				a(1, 0) + b(0, 1) = (0, 0)
			\]
			segue que $a = b = 0$.
		\item Considere o $\real$-espaço vetorial $\real^2$. O conjunto $\{(1, 2); (1, 3)\}$ é linearmente independente, 
			pois vimos no exemplo anterior que para todo $(x, y) \in \real^2$, existem únicos 
			$a$, $b \in \real$ dados por $a = 3x - y$ e $b = y - 2x$, de modo que
			\[
				a(1, 1) + b(1, 3) = (x, y).
			\]
			Assim se $a$, $b \in \real$ são tais que
			\[
				a(1, 2) + b(1, 3) = (x, y)
			\]
			então segue que $a = b = 0$.

		\item No $\real$-espaço vetorial $\real^3$ o conjunto $\{v_1 = (1, -2, 3), v_2 = (5, 6, -1), v_3 = (3, 2, 1)\}$ é linearmente dependente. De fato,
			sejam $x$, $y$ e $z \in \real$ tais que
			\begin{align*}
				xv_1 + yv_2 + zv_3 &= (0, 0, 0)\\
				x(1, -2, 3) + y(5, 6, -1) + z(3, 2, 1) &= (0, 0, 0)\\
				(x, -2x, 3x) + (5y, 6y, -y) + (3z, 2z, z) &= (0, 0, 0)\\
				(x + 5y + 3z, -2x + 6y + 2z, 3x - y + z) &= (0, 0, 0)
			\end{align*}
			que resulta no sistema linear homogêneo:
			\[
				\begin{cases}
					x + 5y + 3z = 0\\
					-2x + 6y + 2z = 0\\
					3x - y + z = 0
				\end{cases}
			\]
			Escalonando esse sistema:
			\begin{align*}
				\begin{bmatrix}
					\phantom{-} 1 & \phantom{-} 5 & 3\\
					-2 & \phantom{-} 6 & 2\\
					\phantom{-} 3 & -1 & 1
				\end{bmatrix}
				\begin{array}{l}
					\phantom{x}\\L_2 \to L_2 + 2L_1\\L_3 \to L_3 - 3L_1
				\end{array}&\sim
				\begin{bmatrix}
					1 & \phantom{-} 5 & \phantom{-} 3\\
					0 & \phantom{-} 16 & \phantom{-} 8\\
					0 & -16 & -8
				\end{bmatrix}
				\begin{array}{l}
					\phantom{x}\\L_2 \to (-1/16)L_2\phantom{x}
				\end{array}\\&\sim
				\begin{bmatrix}
					1 & \phantom{-} 5 & \phantom{-} 3\\
					0 & \phantom{-} 1 & \phantom{-} 1/2\\
					0 & -16 & -8
				\end{bmatrix}
				\begin{array}{l}
					\phantom{x}\\\phantom{x}\\L_3 \to L_3 + 16L_2
				\end{array}\\&\sim
				\begin{bmatrix}
					1 & 5 & 3\\
					0 & 1 & 1/2\\
					0 & 0 & 0
				\end{bmatrix}
			\end{align*}
			cuja solução é dada por $y = -z/2$, $x =-z/2$, $z \in \real$. Portanto esse
			sistema homogêneo admite solucão não trivial e então o conjunto
			$\{v_1 = (1, -2, 3), v_2 = (5, 6, -1), v_3 = (3, 2, 1)\}$ é linearmente dependente.

		\item No $\rac$-espaço vetorial $M_2(\rac)$ considere os vetores
			\[
				v_1 = \begin{bmatrix}1 & 0\\1 & 1\end{bmatrix},
				v_2 = \begin{bmatrix}-1 & 1\\\phantom{-} 1 & 0\end{bmatrix},
				v_3 = \begin{bmatrix}-2 & 2\\\phantom{-} 3 & 4\end{bmatrix}.
			\]
			O conjunto $\{u_1, u_2, u_3\}$ é L.D. ou L.I.?
			\begin{solucao}
				Para determinar isso, sejam $x$, $y$ e $z \in \rac$ tais que
				\[
					xu_1 + yu_2 + zu_3 = 0_{M_2(\rac)}.
				\]
				Temos
				\begin{align*}
					x\begin{bmatrix}1 & 0\\1 & 1\end{bmatrix}
					+ y\begin{bmatrix}-1 & 1\\\phantom{-} 1 & 0\end{bmatrix}
					+ z\begin{bmatrix}-2 & 2\\\phantom{-} 3 & 4\end{bmatrix}
															 &= \begin{bmatrix}0 & 0\\0 & 0\end{bmatrix}
					\\\begin{bmatrix}x & 0\\x & x\end{bmatrix}
					+ \begin{bmatrix}-y & y\\\phantom{-} y & 0\end{bmatrix}
					+ \begin{bmatrix}-2z & 2z\\\phantom{-} 3z & 4z\end{bmatrix}
															 &= \begin{bmatrix}0 & 0\\0 & 0\end{bmatrix}.
					\\\begin{bmatrix} x - y - 2z & y + 2z\\x + y + 3z & x + 4z\end{bmatrix} &= \begin{bmatrix}0 & 0\\0 & 0\end{bmatrix}
				\end{align*}
				com isso obtemos o sistema homogêneo:
				\[
					\begin{cases}
						x - y - 2z = 0\\
						y + 2z = 0\\
						x + y + z = 0\\
						x + 4z = 0
					\end{cases}
				\]
				Escalonando
				\begin{align*}
					\begin{bmatrix}
						1 & -1 & -2\\
						0 & \phantom{-} 1 & \phantom{-} 2\\
						1 & \phantom{-} 1 & \phantom{-} 1\\
						1 & \phantom{-} 0 & \phantom{-} 4
					\end{bmatrix}
					\begin{array}{l}
						\phantom{x}\\\phantom{x}\\L_3 \to L_3 - L_1\\L_4 \to L_4 - L_1
					\end{array}&\sim
					\begin{bmatrix}
						1 & -1 & -2\\
						0 & \phantom{-} 1 & \phantom{-} 2\\
						0 & \phantom{-} 2 & \phantom{-} 3\\
						0 & \phantom{-} 0 & \phantom{-} 6
					\end{bmatrix}
					\begin{array}{l}
						\phantom{x}\\\phantom{x}\\L_3 \to L_3 - 2L_1\\L_4 \to L_4 - L_2
					\end{array}\\&\sim
					\begin{bmatrix}
						1 & -1 & -2\\
						0 & \phantom{-} 1 & \phantom{-} 2\\
						0 & \phantom{-} 0 & -1\\
						0 & \phantom{-} 0 & \phantom{-} 4
					\end{bmatrix}
					\begin{array}{l}
						\phantom{x}\\\phantom{x}\\L_3 \to -L_3\\\phantom{x}
					\end{array}\\&\sim
					\begin{bmatrix}
						1 & -1 & -2\\
						0 & \phantom{-} 1 & \phantom{-} 2\\
						0 & \phantom{-} 0 & \phantom{-} 1\\
						0 & \phantom{-} 0 & \phantom{-} 4
					\end{bmatrix}
					\begin{array}{l}
						\phantom{x}\\\phantom{x}\\\phantom{x}\\L_4 \to L_4 - 4L_3
					\end{array}\\&\sim
					\begin{bmatrix}
						1 & -1 & -2\\
						0 & \phantom{-} 1 & \phantom{-} 2\\
						0 & \phantom{-} 0 & \phantom{-} 1\\
						0 & \phantom{-} 0 & \phantom{-} 0
					\end{bmatrix}
				\end{align*}
				Logo a solução do sistema é $x = y = z = 0$ e então o conjunto $\{u_1, u_2, u_3\}$ é linearmente independente.
			\end{solucao}
			
		\item No espaço vetorial
			\[
				\mathcal{P}_5(\real) = \{a_0 + a_1x + a_2x^2 + a_3x^3 + a_4x^4 + a_5x^5 \mid a_i \in \real, i = 0, 1, \dots, 5 \}
			\]
			sobre $\real$ o conjunto $\{1, x, x^2, x^3, x^4, x^5\}$ é linearmente independente.
			\begin{solucao}
				De fato, sejam $\alpha_0$, $\alpha_1$, $\alpha_2$, $\alpha_3$, $\alpha_4$, $\alpha_5 \in \real$ tais que
				\[
					\alpha_0 + \alpha_1x + \alpha_2x^2 + \alpha_3x^3 + \alpha_4x^4 + \alpha_5x^5 = 0.
				\]
				Essa expressão significa que o polinômio $p(x) = \alpha_0 + \alpha_1x + \alpha_2x^2 + \alpha_3x^3 + \alpha_4x^4 + \alpha_5x^5$ possui infinitas raizes em $\real$, o que é impossível. Logo
				$\alpha_0 = \alpha_1 = \alpha_2 = \alpha_3 = \alpha_4 = \alpha_5 = 0$ e com isso o conjunto $\{1, x, x^2, x^3, x^4, x^5\}$ é linearmente independente.
			\end{solucao}
			
		\item Seja $V$ um $\cp{K}$-espaço vetorial. Dados vetores não nulos $v_1$ e $v_2$ em $V$ então o conjunto $\{v_1, v_2\}$ é linearmente dependente quando existem escalares não nulos $a$, $b \in \cp{K}$
			tais que
			\begin{align*}
				av_1 + bv_2 &= 0_v\\
				av_1 &= -bv_2\\
				v_1 &= -\dfrac{b}{a}v_2
			\end{align*}
			Fazendo $-b/a = \lambda \in \cp{K}$ podemos escrever
			\[
				v_1 = \lambda v_2 \mbox{ ou } v_2 = \dfrac{1}{\lambda}v_1.
			\]
			Portanto, um conjunto contendo somente dois vetores é linearmente dependente se, e somente se, os vetores são múltiplos escalares um do outro.
	\end{enumerate}
\end{exemplos}

\begin{proposicao}
  Seja $V$ um espaço vetorial sobre $\cp{K}$. Então:
  \begin{enumerate}[label={\roman*})]
    \item O vetor nulo é linearmente dependente.

    \item Todo vetor $v \ne 0_V$  é linearmente independente.
    
    \item Dado um conjunto de vetores $\{v_1, v_2, \dots, v_n\}$  se $v_i = 0_V$ para algum $i$,  então $\{v_1, v_2, \dots, v_n\}$ é L.D.

    \item Se os vetores $\{v_1, v_2, \dots, v_n\}$ são L.D.,  então qualquer outro conjunto de vetores que contenha $\{v_1, v_2, \dots, v_n\}$  também é L.D. 
    
    \item Se $\{v_1, v_2, \dots, v_n\}$ é L.I.,  então qualquer subconjunto $\{v_{i_1}, v_{i_2}, \dots, v_{i_s}\}$  com $s < n$ também é L.I. 
    
    \item Seja $\{v_1, v_2, \dots, v_n\}$ um conjunto L.I.  Se $w$ é um vetor de $V$ tal que $\{v_1, v_2, \dots, v_n, w\}$  é L.D.,  então $w$ é uma combinação linear de $v_1$, $v_2$, \dots, $v_n$.
  \end{enumerate}
\end{proposicao}

\begin{observacao}
	Seja $V$ um $\cp{K}$-espaço vetorial. Se todo subconjunto próprio de $\{v_1, v_2, \dots, v_n\}$, isto é, todo subconjunto diferente de $\{v_1, v_2, \dots, v_n\}$ é L.I. não quer dizer que
	$\{v_1, v_2, \dots, v_n\}$ é L.I.. Por exemplo, seja $V= \real^2$ um $\real$-espaço vetorial e considere o conjunto $\{(1,2), (1, 3), (1, 4)\}$. Observe que
	\begin{enumerate}
		\item $\{(1,2)\}$ é L.I.
		\item $\{(1,4)\}$ é L.I.
		\item $\{(1,5)\}$ é L.I.
		\item $\{(1,2);(1,3)\}$ é L.I.
		\item $\{(1,2);(1,5)\}$ é L.I.
		\item $\{(1,3);(1,5)\}$ é L.I.
	\end{enumerate}
	e no entanto $\{(1, 2); (1, 3); (1, 5)\}$ é L.D. pois, por exemplo,
	\[
		2(1, 2) - 3(1, 3) + (1, 5) = (0, 0).
	\]
\end{observacao}
\begin{proposicao}
  Sejam $V$ um $\cp{K}$-espaço vetorial,  $n \ge 2$ e $\{v_1, v_2, \dots, v_n\}$ vetores de $V$.  Então $\{v_1, v_2, \dots, v_n\}$ é L.D.  se, e somente se, pelo menos um vetor $v_j$  for 
  combinação linear dos demais $n - 1$ de $\{v_1, v_2, \dots, v_n\}$.
\end{proposicao}

\begin{definicao}
  Seja $V$ um $\cp{K}$-espaço vetorial.  Um conjunto de vetores $\{v_1, v_2, \dots, v_n\}$  é chamado de uma \textbf{base}  de $V$ se: 
  \begin{enumerate}[label={\roman*})]
    \item $\{v_1, v_2, \dots, v_n\}$ é L.I. 

    \item $V = Span(v_1, v_2, \dots, v_n)$,  ou seja, $\{v_1, v_2, \dots, v_n\}$ gera $V$.
  \end{enumerate}
\end{definicao}

\begin{teorema}
  Seja $V$ um espaço vetorial sobre $\cp{K}$.  Se $\{v_1, v_2, \dots, v_n\}$ é uma base de $V$,  então todo conjunto de vetores de $V$  com mais de $n$ elementos  é L.D. 
\end{teorema}

\begin{corolario}
  Dado um $\cp{K}$-espaço vetorial $V$,  então quaisquer duas bases de $V$ possuem o mesmo número de vetores.
\end{corolario}

\begin{definicao}
  Seja $V$ um espaço vetorial sobre $\cp{K}$.  A \textbf{dimensão} de $V$  é o número de vetores de uma base de $V$,  quando essa base é constituída de uma quantidade finita de vetores. 
  Nesse caso vamos denotar esse número por $\dim_\cp{K}V$  ou simplesmente $\dim V$. 
\end{definicao}

\begin{observacoes}
  \begin{enumerate}[label={\roman*})]
    \item Se $V$ não possui base,  então $\dim V = 0$. 

    \item Se $V$ possui uma base com infinitos vetores,  então $\dim V = \infty$.
  \end{enumerate}
\end{observacoes}

\begin{exemplos}
	Considere $V = \real^2$ um espaço vetorial sobre $\real$. 
	\begin{enumerate}
		\item Já vimos que o conjunto $\{(1, 0); (0, 1)\}$ é L.I. e gera $\real^2$. Logo o conjunto $\{(1, 0); (0, 1)\}$ é uma base
			para $\real^2$, como um $\real$-espaço vetorial.

			Mais ainda, vimos também que o conjunto $\{(1, 2); (1, 3)\}$ também é L.I. e gera $\real^2$. Portanto o conjunto $\{(1, 2); (1, 3)\}$ também é uma base
			para $\real^2$, como um $\real$-espaço vetorial.

			Com isso um espaço vetorial $V$ não possui somente uma única base, mas todas as bases terão o mesmo número de vetores, como veremos em breve.

		\item O conjunto $\{(1, 2); (1, 3); (1, 5)\}$ não é uma base para $\real^2$. Apesar desse conjunto gerar $\real^2$ ele não é linearmente independente. Logo não é uma base.

		\item O conjunto $\{(0, 1)\}$ é linearmente independente mas não gera $\real^2$. Portanto também não é uma base para $\real^2$.
	\end{enumerate}
\end{exemplos}

As bases que aparecem nos seguintes exemplos são chamadas de \textbf{bases canônicas} dos espaços vetoriais $V$ sobre o corpo $\cp{K}$ dado.
\begin{exemplos}
	\begin{enumerate}
		\item Considerendo $V = \real$, $\cp{K} = \real$ uma base para esse espaço é dada pelo conjunto $\mathcal{B} = \{1\}$ pois tal conjunto é L.I. e gera $V$. Portanto $\dim_\real\real = 1$.

		\item Considerendo $V = \cp{K}^n$, $\cp{K}$ uma base para esse espaço é dada pelo conjunto $\mathcal{B} = \{e_1, e_2, e_3, \dots, e_n\}$ onde
			\begin{align*}
				e_1 &= (1, 0, 0, \dots, 0)\\
				e_2 &= (0, 1, 0, \dots, 0)\\
				e_3 &= (0, 0, 1, \dots, 0)\\
						&\vdots\\
				e_n &= (0, 0, 0, \dots, 1)
			\end{align*}
			pois tal conjunto é L.I. e gera $V$. Portanto $\dim_\cp{K}\cp{K} = n$.

		\item Seja $V = M_2(\real)$ um $\real$-espaço vetorial. Sejam
			\[
				E_{11} = \begin{bmatrix}1 & 0\\0 & 0\end{bmatrix},
				E_{12} = \begin{bmatrix}0 & 1\\0 & 0\end{bmatrix},
				E_{21} = \begin{bmatrix}0 & 0\\1 & 0\end{bmatrix},
				E_{22} = \begin{bmatrix}0 & 0\\0 & 1\end{bmatrix}.
			\]
			Então o conjunto $\mathcal{B} = \{E_{11}, E_{12}, E_{21}, E_{22}\}$ é L.I. e gera $M_2(\real)$. Logo é uma base para $M_2(\real)$ como um $\real$-espaço vetorial. Portanto $\dim_\real M_2(\real) = 4$.

		\item Agora seja $V = M_2(\complex)$ um $\real$-espaço vetorial. Tomando as matrizes
			\[
				E_{11} = \begin{bmatrix}1 & 0\\0 & 0\end{bmatrix},
				E_{12} = \begin{bmatrix}0 & 1\\0 & 0\end{bmatrix},
				E_{21} = \begin{bmatrix}0 & 0\\1 & 0\end{bmatrix},
				E_{22} = \begin{bmatrix}0 & 0\\0 & 1\end{bmatrix},
			\]
			vemos que o conjunto $\mathcal{B} = \{E_{11}, E_{12}, E_{21}, E_{22}\}$ é L.I. mas não gera $M_2(\real)$. Por exemplo, não existes escalares reais $x$, $y$, $z$ e $w$ tais que
			\[
				\begin{bmatrix}i & 0 \\0 & 0\end{bmatrix} = xE_{11} + yE_{12} + zE_{21} + wE_{22}.
			\]
			Nesse caso precisamos adicionar as matrizes
			\[
				F_{11} = \begin{bmatrix}i & 0\\0 & 0\end{bmatrix},
				F_{12} = \begin{bmatrix}0 & i\\0 & 0\end{bmatrix},
				F_{21} = \begin{bmatrix}0 & 0\\i & 0\end{bmatrix},
				F_{22} = \begin{bmatrix}0 & 0\\0 & i\end{bmatrix},
			\]
			Com a adição dessa matrizes o conjunto $\mathcal{B} = \{E_{12}, E_{12}, E_{21}, E_{22}, F_{12}, F_{12}, F_{21}, F_{22}\}$ continua sendo linearmente independente e gera $V = M_2(\complex)$
			como um $\real$-espaço vetorial Logo é uma base para $M_2(\complex)$ como um $\real$-espaço vetorial. Portanto $\dim_\real M_2(\complex) = 8$.

			\item Seja $V = M_2(\complex)$ um $\complex$-espaço vetorial. Sejam
			\[
				E_{11} = \begin{bmatrix}1 & 0\\0 & 0\end{bmatrix},
				E_{12} = \begin{bmatrix}0 & 1\\0 & 0\end{bmatrix},
				E_{21} = \begin{bmatrix}0 & 0\\1 & 0\end{bmatrix},
				E_{22} = \begin{bmatrix}0 & 0\\0 & 1\end{bmatrix}.
			\]
			Então o conjunto $\mathcal{B} = \{E_{11}, E_{12}, E_{21}, E_{22}\}$ é L.I. e gera $M_2(\complex)$. Logo é uma base para $M_2(\complex)$ como um $\complex$-espaço vetorial. 
			Portanto $\dim_\complex M_2(\complex) = 4$.

		\item Seja $V = M_{p \times q}(\cp{K})$ um $\cp{K}$-espaço vetorial. Tome as matrizes $E_{ij}$ definidas como
			\[
				E_{ij} = \begin{cases}a_{ij} = 1\\0, \mbox{caso contrário}\end{cases}
			\]
			Então o conjunto $\mathcal{B} = \{E_{11}, E_{12}, \dots, E_{1q}, E_{21}, E_{22}, \dots, E_{2q}, \dots, E_{p1}, E_{p2}, \dots, E_{pq}\}$ é linearmente independente e 
			gera $V = M_{p \times q}(\cp{K})$ como um $\cp{K}$-espaço vetorial. Logo é uma base para $V = M_{p \times q}(\cp{K})$ como um $\cp{K}$-espaço vetorial 
			e com isso, $\dim_{\cp{K}}M_{p \times q}(\cp{K}) = pq$.

		\item Se $V = \{0_v\}$ então $V$ não possui base. Apesar do conjunto $\{0_v\}$ gerar $V$ ele não é linearmente independente. Portanto $\dim_\cp{K}V = 0$.

		\item Considere $V = \mathcal{P}_n(\real) = \{a_0 + a_1x + a_2x^2 + \cdots, a_{n - 1}x^{n - 1} + a_nx^n \mid a_i \in \real, i = 0, 1, 2, \dots, n - 1, n\}$ um $\real$-espaço vetorial. 
			Então o conjunto $\mathcal{B} = \{1, x, x^2, \dots, x^{n - 1}, x^n\}$ é L.I. e gera $V$. Logo é uma base para $V$ como um $\real$-espaço vetorial. Portanto $\dim_\real\mathcal{P}_n(\real) = n + 1$.

		\item Agora considere
			\[
				V = \mathcal{P}(\real) = \{a_0 + a_1x + a_2x^2 + \cdots + a_mx^m \mid a_i \in \real,\ 0 \le i \le m,\ m \in \n\}
			\]
			como um $\real$-espaço vetorial. Então $V$ não possui uma base contendo uma quantidade finita de vetores. De fato, suponha que o conjunto $\mathcal{B} = \{1, x, x^2, \dots, x^m\}$ seja uma base para $V$.
			Então $V = Span(1, x, x^2, \dots, x^m)$. Mas o vetor $x^{m + 1} \in V$, logo existem escalares, não todos nulos, tais que
			\[
				x^{m + 1} = b_0 + b_1x + b_2x^2 + \cdots + b_mx^m
			\]
			que é a mesma coisa que escrever
			\[
				x^{m + 1} - b_mx^m - \cdots - b_2x^2 - b_1x - b_0 = 0.
			\]
			Dessa última expressão segue que o polinômio $p(x) = x^{m + 1} - b_mx^m - \cdots - b_2x^2 - b_1x - b_0$ possui infinitas raizes reais. O que é impossível e então o 
			conjunto $\mathcal{B} = \{1, x, x^2, \dots, x^m\}$ não gera $V = \mathcal{P}(\real)$ para nenhum $m \in \n$. Portanto $\dim_\real\mathcal{P}(\real) = \infty$.
	\end{enumerate}
\end{exemplos}
%\begin{proposicao}
%	Se $W_1$ e $W_1$ s\~ao subespa\c{c}os de um $\cp{K}$-espa\c{c}o vetorial $V$ ent\~ao
%	\begin{enumerate}[label={\roman*})]
%		\item $W_1 \cap W_2$ \'e um subespa\c{c}o vetorial de $V$. De fato, $W_1 \cap W_2$ \'e um subespa\c{c}o tanto de $W_1$ quanto de $W_2$.
%		\item $W_1 + W_2 = \{u_1 + u_2 \mid u_1 \in W_1, u_2 \in W_2\}$ \'e um subespa\c{c}o vetorial de $V$.
%	\end{enumerate}
%\end{proposicao}
%\begin{prova}
%	Exerc{\'\i}cio!
%\end{prova}
%
%\begin{proposicao}
%	Seja $V$ um $\cp{K}$-espa\c{c}o vetorial n\~ao nulo e de dimens\~ao finita. Se $W$ \'e um subespa\c{c}o n\~ao trivial de $V$, ent\~ao $\dim_\cp{K} W < \dim_\cp{K} V$.
%\end{proposicao}
%\begin{prova}
%	Seja $\mathcal{B} = \{w_1, \dots,w_n\}$ uma base de $W$. Em particular $\mathcal{B}$ \'e um conjunto L.I. de $V$. Como $W \ne V$, existe $u \in V$ tal que $u \notin W$ e assim $u$ n\~ao \'e gerado pelos elementos de $\mathcal{B}$. Da{\'\i} pela Proposi\c{c}\~ao \ref{ampliarconjuntoLI}, $\{w_1, \dots,w_n,u\}$ \'e L.I..Logo, uma base de $V$ conter\'a mais elementos que o conjunto $\mathcal{B}$, isto \'e, $\dim_\cp{K} W < \dim_\cp{K} V$.
%\end{prova}
%
%\begin{proposicao}
%	Sejam $V$ um $\cp{K}$-espa\c{c}o vetorial, $W_1$ e $W_2$ subespa\c{c}os vetoriais de $V$, ambos de dimens\~ao finita. Ent\~ao
%	\[
%		\dim_\cp{K}(W_1 + W_2) = \dim_\cp{K}W_1 + \dim_\cp{K}W_2 - \dim_\cp{K}(W_1 \cap W_2).
%	\]
%\end{proposicao}
%\begin{prova}
%	Vamos supor primeiro que $W_1 \cap W_2 \ne \{0_V\}$. Como $W_1$ e $W_2$ s\~ao de dimens\~ao finita, ent\~ao $W_1 \cap W_2$ e $W_1 + W_2$ tamb\'em o s\~ao. Assim seja $\mathcal{B} = \{w_1, \dots,w_n\}$ uma base de $W_1 \cap W_2$. Como $W_1 \cap W_2$ \'e um subespa\c{c}o vetorial tanto de $W_1$ como de $W_2$, pelo Teorema \ref{basecontendoconjuntoLI} podemos estender $\mathcal{B}$ a uma base de $W_1$ e a uma base de $W_2$. Sejam $\mathcal{B}_1 = \{w_1,\dots,w_n,v_1,\dots,v_r\}$ uma base de $W_1$ e $\mathcal{B}_2 = \{w_1,\dots,w_n,u_1,\dots,u_p\}$ uma base de $W_2$. Note que $\mathcal{B} \sub \mathcal{B}_1$ e $\mathcal{B} \sub \mathcal{B}_2$. Vamos ent\~ao mostrar que $\mathcal{A} = \{w_1,\dots,w_n,v_1,\dots,v_r,u_1,\dots,u_p\}$ \'e uma base de $W_1 + W_2$. Primeiro mostraremos que $\mathcal{A}$ gera $W_1 + W_2$.
%
%	Seja $v \in W_1 + W_2$. Ent\~ao $v = x + y$ onde $x \in W_1$ e $y \in W_2$. Mas $\mathcal{B}_1$ e $\mathcal{B}_2$ s\~ao bases de $W_1$ e $W_2$, respectivamente. Assim
%	\begin{align*}
%		x = \sum_{i = 1}^n \alpha_i w_i + \sum_{j = 1}^r\beta_j v_j \\
%		y = \sum_{i = 1}^n \delta_i w_i + \sum_{l = 1}^p\gamma_l u_l
%	\end{align*}
%	com $\alpha_i$, $\beta_j$, $\delta_i$, $\gamma_l \in \cp{K}$. Da{\'\i}
%	\[
%		v = x + y = \sum_{i = 1}^n(\alpha_i + \delta_i)w_i + \sum_{j = 1}^r\beta_jv_j + \sum_{l = 1}^p\gamma_lu_l
%	\]
%	e ent\~ao $\mathcal{A}$ gera $W_1 + W_2$.
%
%	Agora, precisamos mostrar que $\mathcal{A}$ \'e L.I.. Considere ent\~ao a soma
%	\[
%		\sum_{i = 1}^n\alpha_iw_i + \sum_{j = 1}^r\beta_jv_j + \sum_{l = 1}^p\gamma_lu_l = 0_V
%	\]
%	onde $\alpha_i$, $\beta_j$, $\gamma_l \in \cp{K}$. Assim
%	\begin{equation}\label{equacaoauxiliar}
%		\sum_{l = 1}^p\gamma_lu_l = \sum_{i = 1}^n(-\alpha_i)w_i + \sum_{j = 1}^r(-\beta_j)v_j \in W_1 \cap W_2
%	\end{equation}
%	pois \'e uma combina\c{c}\~ao linear de elementos de $\mathcal{B}_1$ e de $\mathcal{B}_2$, simultaneamente. Logo, existem $\lambda_1$, \dots, $\lambda_n \in \cp{K}$ tais que
%	\[
%		\sum_{l = 1}^p\gamma_lu_l = \sum_{i = 1}^n\lambda_iw_i
%	\]
%	isto \'e,
%	\[
%		\sum_{l = 1}^p\gamma_lu_l + \sum_{i = 1}^n(-\lambda_i)w_i = 0_V.
%	\]
%	Mas $\mathcal{B}$ \'e L.I., da{\'\i} $\gamma_1 = \cdots = \gamma_p = \lambda_1 = \cdots = \lambda_n = 0_\cp{K}$. Assim podemos reescrever \eqref{equacaoauxiliar} como
%	\[
%		\sum_{i = 1}^n(-\alpha_i)w_i + \sum_{j = 1}^r(-\beta_j)v_j = 0_\cp{K}.
%	\]
%	Mas $\mathcal{B}_1$ \'e L.I., donde $\alpha_1 = \cdots = \alpha_n = \beta_1 = \cdots = \beta_r = 0_\cp{K}$. Isto \'e, $\mathcal{A}$ \'e L.I..
%
%	Portanto $\mathcal{A}$ \'e uma base de $W_1 + W_2$ e assim
%	\[
%		\dim_\cp{K}(W_1 + W_2) = \dim_\cp{K}W_1 + \dim_\cp{K}W_2 - \dim_\cp{K}(W_1 \cap W_2).
%	\]
%
%	Se $W_1 \cap W_2 = \{0_V\}$, sejam $\mathcal{B}_1$ e $\mathcal{B}_2$ bases de $W_1$ e $W_2$, respectivamente. Analogamente ao caso anterior, mostra-se que $\mathcal{B}_1 \cup \mathcal{B}_2$ \'e uma base de $W_1 + W_2$.
%\end{prova}
%
%\begin{definicao}\index{Subespa\c{c}o!gerado}
%	Seja $V$ um $\cp{K}$-espa\c{c}o vetorial e $S = \{u_1,\dots,u_n\} \sub V$. O \textbf{subespa\c{c}o gerado} por $S$ \'e definido como o subconjunto de $V$ formado por todas as combina\c{c}\~oes lineares de $u_1$, \dots, $u_n$. Denotaremos tal conjunto por
%	\[
%		[u_1,\dots,u_n] = \{\alpha_1u_1 + \cdots + \alpha_nu_n \mid \alpha_1, \dots, \alpha_n \in \cp{K}\}.
%	\]
%\end{definicao}
%
%\begin{proposicao}
%	Seja $V$ um $\cp{K}$-espa\c{c}o vetorial e $\{v_1,\dots,v_n\} \sub V$. O conjunto $[v_1,\dots,v_n]$ \'e um $\cp{K}$-subespa\c{c}o vetorial de $V$.
%\end{proposicao}
%
%\begin{exemplo}
%	\begin{enumerate}[label={\arabic*})]
%		\item Dado $\mathcal{P}(\complex)$ o $\complex$-espa\c{c}o vetorial dos polin\^omios com coeficientes em $\complex$, seja $\{1,x,x^2,x^3,x^4\} \sub \mathcal{P}(\complex)$. Ent\~ao
%		      \[
%			      [1,x,x^2,x^3,x^4] = \{a_0 + a_1x + a_2x^2 + a_3x^3 + a_4x^4\} = \{f(x) \in \mathcal{P}(\complex) \mid \deg f(x) \le 4\}
%		      \]
%		      \'e um subespa\c{c}o de $\mathcal{P}(\complex)$.
%		\item Considere $\real^5$ como um $\real$-espa\c{c}o vetorial e seja $\{(1,2,0,3,0);(0,0,1,4,0);(0,0,0,0,1)\}$. Ent\~ao
%		      \[
%			      [(1,2,0,3,0);(0,0,1,4,0);(0,0,0,0,1)] = \{(\alpha, 2\alpha,\beta,3\alpha + 4\beta,\gamma) \mid \alpha, \beta, \gamma \in \real\}
%		      \]
%		      \'e um subespa\c{c}o vetorial de $\real^5$.
%		\item Considere $W = [(1,2,3);(0,1,2);(-1,0,1)]$ um $\real$-espa\c{c}o vetorial. Determinar $\dim_\real W$.
%		      \begin{solucao}
%			      Inicialmente, vamos verificar se o conjunto $\{(1,2,3);(0,1,2);(-1,0,1)\}$ \'e L.I. ou L.D.. Para isso, sejam $x$, $y$ e $z \in \real$ tais que
%			      \[
%				      x(1,2,3) + y(0,1,2) + z(-1,0,1) = (0,0,0).
%			      \]
%			      Assim vemos que $x = z$ e $y = -2z$ s\~ao solu\c{c}\~oes para o sistema
%			      \[
%				      \begin{cases}
%					      x - z = 0  \\
%					      2x + y = 0 \\
%					      3x + 2y + z = 0
%				      \end{cases}
%			      \]
%			      e com isso $\{(1,2,3);(0,1,2);(-1,0,1)\}$ \'e L.D. Da{\'\i} $\dim_\real W \le 2$. Agora note que $(1,2,3)$ n\~ao \'e m\'ultiplo escalar de $(0,1,2)$. Logo, $\{(1,2,3); (0,1,2)\}$ \'e L.I. e ent\~ao $\dim_\real W = 2$.
%		      \end{solucao}
%
%		\item Seja $V = \mathcal{P}_4(\real)$. Determine uma base de $V$ contendo os polin\^omios
%		      \begin{align*}
%			       & p_1(x) = 1 + 2x - x^2 + 3x^3 + 2x^4   \\
%			       & p_2(x) = 2 + 4x + x^2 + 6x^3 + 3x^4   \\
%			       & p_3(x) = 1 + 2x + 2x^2 + 3x^3 + 2x^4.
%		      \end{align*}
%		      \begin{solucao}
%			      Sabemos que $\mathcal{B} = \{1,x,x^2,x^3,x^4\}$ \'e uma base de $\mathcal{P}_4(\real)$. Tal base \'e chamada de \textbf{base can\^onica} de $\mathcal{P}_4(\real)$. Assim $\dim_\real \mathcal{P}_4(\real) = 5$. Para determinar uma base contendo $p_1(x)$, $p_2(x)$ e $p_3(x)$, come\c{c}amos determinando se tais vetores s\~ao L.I. ou L.D.. Para isso montamos a matriz
%			      \[
%				      A = \begin{bmatrix}
%					      \phantom{-}1 & 2 & 1 \\
%					      \phantom{-}2 & 4 & 2 \\
%					      -1           & 1 & 2 \\
%					      \phantom{-}3 & 6 & 3 \\
%					      \phantom{-}2 & 3 & 2
%				      \end{bmatrix}.
%			      \]
%			      Aplicando as opera\c{c}\~oes elementares em $A$ para reduz{\'\i}-la a forma em escada
%			      \begin{align*}
%				      A & =
%				      \left[
%					      \begin{array}{ccc}
%						      \phantom{-}1 & 2 & 1 \\
%						      \phantom{-}2 & 4 & 2 \\
%						      -1           & 1 & 2 \\
%						      \phantom{-}3 & 6 & 3 \\
%						      \phantom{-}2 & 3 & 2
%					      \end{array}
%					      \right]
%				      \begin{array}{l}
%					      \phantom{x}        \\
%					      L_2 \to L_2 - 2L_1 \\
%					      L_3 \to L_3 + L_1  \\
%					      L_4 \to L_2 - 3L_1 \\
%					      L_5 \to L_5 - 2L_1
%				      \end{array} \sim
%				      \left[
%					      \begin{array}{ccc}
%						      1 & \phantom{-}2 & 1 \\
%						      0 & \phantom{-}0 & 0 \\
%						      0 & \phantom{-}3 & 3 \\
%						      0 & \phantom{-}0 & 0 \\
%						      0 & -1           & 0
%					      \end{array}
%					      \right] = M.
%			      \end{align*}
%			      Como a matrix $M$ possui posto 3, ent\~ao $\{p_1(x), p_2(x), p_3(x)\}$ \'e L.I. em $\mathcal{P}_4(\real)$. Observe que $M$ n\~ao tem 1 na segunda e quarta linhas. Assim vamos adicionar a $M$ uma coluna com 1 na segunda linha e outra com 1 na quarta linha, obtendo
%			      \[
%				      M' = \begin{bmatrix}
%					      1 & \phantom{-}2 & 1 & 0 & 0 \\
%					      0 & \phantom{-}0 & 0 & 1 & 0 \\
%					      0 & \phantom{-}3 & 3 & 0 & 0 \\
%					      0 & \phantom{-}0 & 0 & 0 & 1 \\
%					      0 & -1           & 0 & 0 & 0
%				      \end{bmatrix}.
%			      \]
%			      Assim $\mathcal{B}' = \{p_1(x), p_2(x), p_3(x),x, x^3\}$ forma uma base de $\mathcal{P}_4(\real)$ contendo $p_1(x)$, $p_2(x)$ e $p_3(x)$.
%		      \end{solucao}
%		\item Considere $V = \cp{M}_{3\times 2}(\real)$. Verifique se o conjunto formado pelas matrizes
%		      \[
%			      A_1 = \begin{bmatrix}
%				      \phantom{-}1 & 0 \\
%				      -1           & 3 \\
%				      \phantom{-}3 & 2
%			      \end{bmatrix}; A_2 = \begin{bmatrix}
%				      0 & -1           \\
%				      2 & \phantom{-}4 \\
%				      3 & \phantom{-}2
%			      \end{bmatrix}; A_3 = \begin{bmatrix}
%				      1 & -2            \\
%				      3 & \phantom{-}11 \\
%				      9 & \phantom{-}6
%			      \end{bmatrix}.
%		      \]
%		      \'e L.D. ou L.I. em $V$.
%		      \begin{solucao}
%			      Considere a matriz $M$ formada pelas entradas das matrizes $A_1$, $A_2$ e $A_3$ escritas como colunas de $M$
%			      \[
%				      M = \begin{bmatrix}
%					      \phantom{-}1 & \phantom{-}0 & \phantom{-}1  \\
%					      \phantom{-}0 & -1           & -2            \\
%					      -1           & \phantom{-}2 & \phantom{-}3  \\
%					      \phantom{-}3 & \phantom{-}4 & \phantom{-}11 \\
%					      \phantom{-}3 & \phantom{-}3 & \phantom{-}9  \\
%					      \phantom{-}2 & \phantom{-}2 & \phantom{-}6
%				      \end{bmatrix}.
%			      \]
%			      Aplicando as opera\c{c}\~oes elementares em $M$:
%			      \begin{align*}
%				      M & =
%				      \left[
%					      \begin{array}{ccc}
%						      \phantom{-}1 & \phantom{-}0 & \phantom{-}1  \\
%						      \phantom{-}0 & -1           & -2            \\
%						      -1           & \phantom{-}2 & \phantom{-}3  \\
%						      \phantom{-}3 & \phantom{-}4 & \phantom{-}11 \\
%						      \phantom{-}3 & \phantom{-}3 & \phantom{-}9  \\
%						      \phantom{-}2 & \phantom{-}2 & \phantom{-}6
%					      \end{array}
%					      \right]
%				      \begin{array}{l}
%					      \phantom{x}        \\
%					      \phantom{x}        \\
%					      L_3 \to L_3 + L_1  \\
%					      L_4 \to L_4 - 3L_1 \\
%					      L_5 \to L_5 - 3L_1 \\
%					      L_6 \to L_6 - 2L_1
%				      \end{array} \sim
%				      \left[
%					      \begin{array}{ccc}
%						      1 & \phantom{-}0 & \phantom{-}1 \\
%						      0 & -1           & -2           \\
%						      0 & \phantom{-}2 & \phantom{-}4 \\
%						      0 & \phantom{-}4 & \phantom{-}8 \\
%						      0 & \phantom{-}3 & \phantom{-}6 \\
%						      0 & \phantom{-}2 & \phantom{-}4
%					      \end{array}
%					      \right]
%				      \begin{array}{l}
%					      \phantom{x}        \\
%					      \phantom{x}        \\
%					      L_3 \to L_3 + 2L_2 \\
%					      L_4 \to L_4 + 4L_2 \\
%					      L_5 \to L_5 + 3L_2 \\
%					      L_6 \to L_6 + 2L_2
%				      \end{array} \\ &\sim
%				      \left[
%					      \begin{array}{ccc}
%						      1 & \phantom{-}0 & \phantom{-}1 \\
%						      0 & -1           & -2           \\
%						      0 & \phantom{-}0 & \phantom{-}0 \\
%						      0 & \phantom{-}0 & \phantom{-}0 \\
%						      0 & \phantom{-}0 & \phantom{-}0 \\
%						      0 & \phantom{-}0 & \phantom{-}0
%					      \end{array}
%					      \right]
%			      \end{align*}
%			      Como a matriz possui posto 2, ent\~ao o vetor $A_3$ \'e uma combina\c{c}\~ao linear de $A_1$ e $A_2$, ou seja, $\{A_1, A_2, A_3\}$ \'e L.D..
%		      \end{solucao}
%	\end{enumerate}
%\end{exemplo}
%% section subespacos (end)
