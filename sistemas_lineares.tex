%!TEX root = IAL.tex

\chapter{Sistemas Lineares}

Ao longo de todo esse capítulo o conjunto $\cp{K}$ será considerado como sendo um dos conjuntos: $\rac$, $\real$ ou $\complex$.

\section{Sistemas Lineares}\label{ssub:sistemas_lineares}
Vamos trabalhar com \textbf{equações lineares}\index{Sistemas Lineares!Equação linear} em $n$ variáveis $x_1$, $x_2$, \dots, $x_n$ que são equações que podem ser escritas na forma
\begin{equation}\label{equacao_linear}
    a_1x_1  + a_2x_2 +  \cdots + a_qx_q  = b,
\end{equation}
onde $a_1$, $a_2$, \dots, $a_q$, $b$ são escalares no corpo $\cp{K}$, sendo que nem todos os coeficientes $a_i$ são nulos.

No caso em que $b = 0$,  a equação \eqref{equacao_linear} tem a forma
\begin{equation}
    a_1x_1 + a_2x_2 + \cdots + a_qx_q = 0
\end{equation}
e é chamada de uma \textbf{equação linear homogênea}\index{Sistemas Lineares!Equação linear homogênea}.

\begin{exemplos}
	\begin{enumerate}
		\item Equações da forma
			\begin{enumerate}
				\item $x_1 + 2x_2 - 3x_3 = 10$, em $\cp{K} = \rac$
				\item $2x_1 + 0x_2 + \sqrt{2}x_3 - 4x_4 = 0$, em $\cp{K} = \real$, que será escrita como $2x_1 + 0x_2 + \sqrt{2}x_3 - 4x_4 = 0$
				\item $ix_1 + (2 +i)x_2 = 3 + 2i$, em $\cp{K} = \complex$
			\end{enumerate}
		são exemplos de \textbf{equações lineares}.

		\item Já equações na forma
			\begin{enumerate}
				\item $x_1^2 + 2x_2 - 3x_3 = 0$ em $\cp{K} = \real$
				\item $x_1 + 2\sin(x_2) + 3x_3 + x_ 4 = 1$ em $\cp{K} = \real$
				\item $2x_1 + 3x_2 - 4x_3^{-1} = 2$ em $\cp{K} = \rac$
			\end{enumerate}
		não são equações lineares e portanto não serão abordadas nesse curso.
	\end{enumerate}
\end{exemplos}

Considerenado $\cp{K} = \real$, queremos analisar um conjuto de equações lineares do tipo:

\begin{align}
    \begin{cases}\label{sistema_linear_2x2}
        ax + by = b_1\\
        cx + dy = b_2
    \end{cases}
\end{align}
onde $a$, $b$, $c$, $d$, $b_1$, $b_2 \in \cp{K}$.

Queremos saber se é possível encontrar valores para $x$, $y$ no conjunto $\real$ de modo que essas duas equações sejam simultaneamente verdadeiras? Caso existam, gostaríamos de determinar todos os possíveis valores que $x$ e $y$ podem assumir.


\definecolor{qqqqff}{rgb}{0,0,1}
\definecolor{ffqqqq}{rgb}{1,0,0}
\begin{center}
    \begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1cm,y=1cm]
        \begin{axis}[
            x=1cm,y=1cm,
            axis lines=middle,
            xticklabels={,,},
            yticklabels={,,},
            xlabel=$x$,
            ylabel=$y$,
            xmin=-2,
            xmax=5,
            ymin=-1.3,
            ymax=3,]
            \draw [line width=5.2pt,dash pattern=on 1pt off 1pt,color=ffqqqq,domain=-1.348257839721257:5.807994044102577] plot(\x,{(--4-1*\x)/2});
            \draw [line width=2pt,color=qqqqff,domain=-1.348257839721257:5.807994044102577] plot(\x,{(--8-2*\x)/4});
            \begin{scriptsize}
                \draw[color=ffqqqq] (1.8,2) node {$a_{11}x + a_{12}y = b_1$};
                \draw[color=qqqqff] (3,1.5) node {$a_{21}x + a_{22}y = b_2$};
            \end{scriptsize}
        \end{axis}
    \end{tikzpicture}
\end{center}

Existem infinitos valores de $x$, $y \in \cp{K}$  que satisfazem as duas equações simultanemente.  Neste caso dizemos que o sistema \eqref{sistema_linear_2x2}  é \textbf{possível e indeterminado}.



\definecolor{ffqqqq}{rgb}{1,0,0}
\definecolor{qqqqff}{rgb}{0,0,1}
\begin{center}
    \begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1cm,y=1cm]
        \begin{axis}[
            x=1cm,y=1cm,
            axis lines=middle,
            xticklabels={,,},
            yticklabels={,,},
            xlabel=$x$,
            ylabel=$y$,
            xmin=-5.3,
            xmax=6.3,
            ymin=-1,
            ymax=4.3,]
            \draw [line width=2pt,color=qqqqff,domain=-5:6] plot(\x,{(--4-1*\x)/5});
            \draw [line width=2pt,color=ffqqqq,domain=-5:6] plot(\x,{(--16-1*\x)/5});
            \begin{scriptsize}
                \draw[color=qqqqff] (-3.8,2.2) node {$a_{21}x + a_{22}y = b_2$};
                \draw[color=ffqqqq] (-3.8,3.4) node {$a_{11}x + a_{12}y = b_1$};
            \end{scriptsize}
        \end{axis}
    \end{tikzpicture}
\end{center}

Não existem valores de $x$, $y \in \cp{K}$  satisfazendo as duas equações simultaneamente.  Nesse caso dizemos que o sistema \eqref{sistema_linear_2x2}  é \textbf{impossível}.




\definecolor{qqqqff}{rgb}{0,0,1}
\definecolor{ffqqqq}{rgb}{1,0,0}
\begin{center}
    \begin{tikzpicture}[line cap=round,line join=round,>=triangle 45,x=1cm,y=1cm]
        \begin{axis}[
            x=1cm,y=1cm,
            axis lines=middle,
            xticklabels={,,},
            yticklabels={,,},
            xlabel=$x$,
            ylabel=$y$,
            xmin=-2,
            xmax=4.3,
            ymin=-2,
            ymax=3.5,]
            \draw [line width=2pt,color=ffqqqq,domain=-4:5] plot(\x,{(--4.94--7.92*\x)/7.58});
            \draw [line width=2pt,color=qqqqff,domain=-4:5] plot(\x,{(--4.824-8.66*\x)/8.24});
            \begin{scriptsize}
                \draw[color=ffqqqq] (2.9,2) node {$a_{11}x + a_{12}y = b_1$};
                \draw[color=qqqqff] (2.7,-0.5) node {$a_{21}x + a_{22}y = b_2$};
            \end{scriptsize}
        \end{axis}
    \end{tikzpicture}
\end{center}

Nesca caso existe um único conjunto de valores $x = \alpha \in \cp{K}$ e $y = \lambda \in \cp{K}$  que satisfaz as duas equações simultaneamente.  Neste caso dizemos que o sistema \eqref{sistema_linear_2x2}  é \textbf{possível e determinado}.



Esse mesmo tipo de análise pode ser aplicada num sistema da forma
\begin{align}
    \begin{cases}\label{sistema_linear_3x3}
        a_1x + a_2y + a_3z = b_1\\
        a_4x + a_5y + a_6z = b_2\\
        a_7x + a_8y + a_9z = b_3
    \end{cases}
\end{align}
onde $a_i \in \cp{K}$ para $1 \le i \le 9$ e $b_j \in \cp{K}$ para $1 \le j \le 3$.

\vspace{.3cm}

Existem valores de $x$, $y$ e $z \in \cp{K}$ que satisfaçam as três equações simultaneamente?



Como no caso anterior, temos as seguintes possibilidades:
\begin{enumerate}[label={\roman*})]
    \item Existe um único conjunto de valores $x = \alpha \in \cp{K}$, $y = \lambda \in \cp{K}$ e $z = \gamma \in \cp{K}$  que satisfaz as três equações simultaneamente.  Neste caso dizemos que o sistema \eqref{sistema_linear_3x3}  é \textbf{possível e determinado}.

    \item Existem infinitos valores de $x$, $y$, $z \in \cp{K}$  que satisfazem as três equações simultanemente.  Neste caso dizemos que o sistema \eqref{sistema_linear_3x3}  é \textbf{possível e indeterminado}.

    \item Não existem valores de $x$, $y$, $z \in \cp{K}$  satisfazendo as três equações simultaneamente.  Nesse caso dizemos que o sistema \eqref{sistema_linear_3x3}  é \textbf{impossível}.
\end{enumerate}




Escolha escalares $b_1$, \dots, $b_m$  e $a_{ij}$,  $1 \le i \le m$, $1 \le j \le n$ todos em $\cp{K}$.

\vspace{.3cm}

Queremos saber se é possível encontrar valores para  $x_1$, $x_2$, \dots, $x_n$  de modo que o seguinte conjunto de equações sejam válidas: 
\begin{equation}\label{sistema_linear_geral}
\begin{cases}
        a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = b_1\\
        a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = b_2\\
        \qquad \vdots\\
        a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n = b_m
    \end{cases}
\end{equation}

O conjunto de equações em \eqref{sistema_linear_geral} é chamado de um  \textbf{sistema de $m$ equa\c{c}\~oes lineares  a $n$ inc\'ognitas} $x_1$, $x_2$, \dots, $x_n$ , ou simplesmente de um \textbf{sistema linear}, nas incógnitas  $x_1$, $x_2$, \dots, $x_n$.



\vspace{.3cm}

Uma solução de um sistema linear do tipo \eqref{sistema_linear_geral}
\[
    x_1 = \alpha_1,  x_2 = \alpha_2,  \dots, x_n = \alpha_n
\]
onde $\alpha_1$, $\alpha_2$, \dots, $\alpha_n \in \cp{K}$,  pode ser escrita como
\[
    (\alpha_1, \alpha_2, \dots, \alpha_n)
\]
e é chamada de uma \textbf{ênupla ordenada} ou uma \textbf{n-upla ordenada}.



Se $b_1 = b_2 = \cdots = b_m = 0_\cp{K} \in K$,  dizemos que o sistema
\begin{equation}\label{sistemalinearhomogeneo}\index{Sistema Linear}
    \begin{cases}
        a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = 0_\cp{K}\\
        a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = 0_\cp{K}\\
        \qquad \vdots\\
        a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n = 0_\cp{K}
    \end{cases}
\end{equation}
\'e um \textbf{sistema linear homog\^eneo}. 

\vspace{.3cm}

Observe que tal sistema sempre possui solu\c{c}\~ao,  a saber, $x_1 = x_2 = \cdots = x_n = 0_\cp{K}$.



\begin{teorema}
    Todo sistema linear do tipo \eqref{sistema_linear_geral} tem zero,  uma  ou uma infinidade de soluções.  Não existem outras possibilidades.
\end{teorema}



No caso de um sistema linear da forma \eqref{sistema_linear_geral},  o processo para encontrar suas soluções ser\'a feito mediante o uso de 3 tipos de opera\c{c}\~oes.  S\~ao elas:
\begin{itemize}
\item[$e_1$)] Troca da posi\c{c}\~ao de duas equa\c{c}\~oes.
\item[$e_2$)] Multiplica\c{c}\~ao de uma equa\c{c}\~ao por um escalar n\~ao nulo.
\item[$e_3$)] Substitui\c{c}\~ao de uma equa\c{c}\~ao pela soma desta equa\c{c}\~ao com alguma outra.
\end{itemize}

Estas tr\^es opera\c{c}\~oes s\~ao chamadas de  \textbf{opera\c{c}\~oes elementares}.



Uma outra matriz que podemos associar ao sistema \eqref{sistema_linear_geral} \'e
\[
\begin{bmatrix}
        a_{11} & a_{12} & \cdots & a_{1n} & b_1\\
a_{21} & a_{22} & \cdots & a_{2n} & b_2\\
\vdots & \vdots & \vdots & \vdots & \vdots\\
a_{m1} & a_{m2} & \cdots & a_{mn} & b_m\\
    \end{bmatrix}
\]

que \'e chamada de \textbf{matriz ampliada do sistema}  ou \textbf{matriz aumentada do sistema}.



Na forma matricial  as opera\c{c}\~oes elementares s\~ao descritas como:

\vspace{.3cm}

\begin{itemize}
    \item[$e_1$)] Trocar a $i$-\'esima linha de $A$  pela $j$-\'esima linha de $A$:  $L_i \leftrightarrow L_j$;

    \vspace{.3cm}

    \item[$e_2$)] Multiplica\c{c}\~ao da $i$-\'esima linha de $A$  por um escalar $\alpha \in \cp{K}$ n\~ao nulo:  $L_i \rightarrow \alpha L_i$;

    \vspace{.3cm}

   \item[$e_3$)] Substitui\c{c}\~ao da $i$-\'esima linha de $A$  pela $i$-\'esima linha mais $\alpha$ vezes a $j$-\'esima linha:  $L_i \rightarrow L_i + \alpha L_j$.
\end{itemize}



\begin{definicao}\label{linhareduzida}
    Uma matriz $A$ $m \times n$ \'e  dita estar na \textbf{forma escalonada reduzida por linhas} se:
    \begin{enumerate}[label={\roman*})]
        \item O primeiro elemento n\~ao nulo  em cada linha n\~ao nula de $A$  \'e $1$.  Dizemos que esse número 1 é um \textbf{pivô}.

        \vspace{.3cm}

        \item Toda linha de $A$ cujos elementos s\~ao todos nulos  ocorre abaixo de todas as linhas que possuem um elemento n\~ao-nulo. 

        \vspace{.3cm}

        \item Se as linhas 1, 2, \dots, $r$ s\~ao as linhas n\~ao-nulas de $A$  e se o \textbf{pivô} da linha $i$ ocorre na coluna $k_i$,  $i = 1$, \dots, $r$,  ent\~ao $k_1 < k_2 < \cdots < k_r$.

        \vspace{.3cm}

        \item Cada coluna de $A$ que cont\'em um \textbf{pivô}  tem todos os seus outros elementos nulos.
    \end{enumerate}
\end{definicao}

\begin{observacao}
    Uma matriz que satisfaz as três primeiras propriedades da definição anterior  é dita estar na \textbf{forma escalonada por linhas},  ou simplesmente, em \textbf{forma escalonada}.
\end{observacao}

Seja $\cp{K}$ um corpo. Consideremos o problema de determinar $n$ escalares, ou seja, $n$ elementos $x_1$, $x_2$, \dots, $x_n$ em $\cp{K}$ que satisfa\c{c}am simultaneamente as equa\c{c}\~oes
\begin{equation}\label{sistemalinear}\index{Sistema Linear}
	\begin{cases}
		a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = b_1\\
		a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = b_2\\
		\qquad \vdots\\
		a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n = b_m\\
	\end{cases}
\end{equation}
onde $b_1$, \dots, $b_m$ e $a_{ij}$, $1 \le i \le m$, $1 \le j \le n$ s\~ao elementos de $\cp{K}$ previamente conhecidos. Chamamos \eqref{sistemalinear} de um \textbf{sistema de $m$ equa\c{c}\~oes lineares a $n$ inc\'ognitas} $x_1$, $x_2$, \dots, $x_n$. Toda $n$-upla $(\alpha_1, \alpha_2, \dots, \alpha_n)$ onde $\alpha_i \in \cp{K}$ para $1 \le i \le n$, que satisfazem a cada uma das equa\c{c}\~oes de \eqref{sistemalinear} \'e chamada de uma \textbf{solu\c{c}\~ao} do sistema.

Se $b_1 = b_2 = \cdots = b_m = 0_\cp{K} \in K$, dizemos que o sistema
\begin{equation}\label{sistemalinearhomogeneo}\index{Sistema Linear}
	\begin{cases}
		a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = 0_\cp{K}\\
		a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = 0_\cp{K}\\
		\qquad \vdots\\
		a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n = 0_\cp{K}\\
	\end{cases}
\end{equation}
\'e um \textbf{sistema linear homog\^eneo}, ou que cada uma de suas equa\c{c}\~oes \'e homog\^enea. Observe que tal sistema sempre possui solu\c{c}\~ao, a saber, $x_1 = x_2 = \cdots = x_n = 0_\cp{K}$.

O m\'etodo mais importante para determinar as solu\c{c}\~oes de um sistema de equa\c{c}\~oes lineares \'e o m\'etodo do \textbf{escalonamento}. Por exemplo, considere o sistema
\begin{equation}\label{exemploplo1}
	\begin{cases}
		2x_1 - x_2 + x_3 = 0\\
		x_1 + 3x_2 + 4x_ 3 = 0
	\end{cases}
\end{equation}
onde o corpo considerado \'e $\real$.

Observe que multiplicando a segunda equa\c{c}\~ao de \eqref{exemploplo1} por $-2$ e somando o resultado \`a primeira equa\c{c}\~ao obtemos
\[
	-7x_2 - 7x_3 = 0
\]
o que resulta em $x_2 = -x_3$. Agora se multiplicarmos a primeira equa\c{c}\~ao de \eqref{exemploplo1} por $3$ e somarmos com a segunda, obtemos
\[
	7x_1 + 7x_3 = 0
\]
e da{\'\i} $x_1 = -x_3$.

Assim para que uma terna $(x_1, x_2, x_3)$ de n\'umeros reais seja solu\c{c}\~ao de \eqref{exemploplo1} deve satisfazer
\[
	x_1 = x_2 = -x_3.
\]
Por outro lado, qualquer terna da forma $(a, a, -a)$ \'e solu\c{c}\~ao de \eqref{exemploplo1}. Portanto a solu\c{c}\~ao de \eqref{exemploplo1} \'e da forma
\[
	(a, a, -a)
\]
onde $a \in \real$.

No caso de um sistema linear da forma \eqref{sistemalinear}, o processo de elemina\c{c}\~ao de vari\'aveis ser\'a feito mediante o uso de 3 tipos de opera\c{c}\~oes. S\~ao elas:
\begin{itemize}
	\item[$e_1$)] Troca da posi\c{c}\~ao de duas equa\c{c}\~oes.
	\item[$e_2$)] Multiplica\c{c}\~ao de uma equa\c{c}\~ao por um escalar n\~ao nulo.
	\item[$e_3$)] Substitui\c{c}\~ao de uma equa\c{c}\~ao pela soma desta equa\c{c}\~ao com alguma outra.
\end{itemize}

Estas tr\^es opera\c{c}\~oes s\~ao chamadas de \textbf{opera\c{c}\~oes elementares}.\index{Opera\c{c}\~oes Elementares}

\begin{exemplo}
	Considere o seguinte sistema sobre o corpo $\real$:
	\[
		\begin{cases}
			x_1 + 4x_2 + 3x_3 = 1\\
			2x_1 + 5x_2 + 4x_3 = 4\\
			x_1 - 3x_2 - 2x_3 = 5
		\end{cases}
	\]
	Efetuando opera\c{c}\~oes elementares podemos escrever:
	\begin{align*}
		&\begin{cases}
			x_1 + 4x_2 + 3x_3 = 1\\
			2x_1 + 5x_2 + 4x_3 = 4 & L_2 \rightarrow L_2 - 2L_1\\
			x_1 - 3x_2 - 2x_3 = 5
		\end{cases} \sim
		\begin{cases}
			x_1 + 4x_2 + 3x_3 = 1\\
			\phantom{0x_1} -3x_2 - 2x_3 = 2\\
			x_1 - 3x_2 - 2x_3 = 5 & L_3 \rightarrow L_2 - L_1
		\end{cases}\\ \\ & \sim
		\begin{cases}
			x_1 + 4x_2 + 3x_3 = 1\\
			\phantom{0x_1} - 3x_2 - 2x_3 = 2 & L_2 \rightarrow (-1/3)L_2\\
			\phantom{0x_1} - 7x_2 - 5x_3 = 4
		\end{cases} \sim
		\begin{cases}
			x_1 + 4x_2 + 3x_3 = 1\\
			\phantom{0x_1} x_2 + (2/3)x_3 = (-2/3)\\
			\phantom{0x_1} - 7x_2 - 5x_3 = 4 & L_3 \rightarrow L_3 + 7L_2
		\end{cases}\\ \\ & \sim
		\begin{cases}
			x_1 + 4x_2 + 3x_3 = 1\\
			\phantom{0x_1} x_2 + (2/3)x_3 = (-2/3)\\
			\phantom{0x_1} \phantom{0x_2}  -(1/3)x_3 = -(2/3)
		\end{cases}
	\end{align*}
	Assim encontramos
	\[
		x_1 = 3, \quad x_2 = -2, \quad x_3 = 2.
	\]
\end{exemplo}

\begin{definicao}\index{Sistemas Equivalentes}
	Dois sistemas de equa\c{c}\~oes lineares s\~ao chamados de \textbf{equivalentes} se, e somente, se toda solu\c{c}\~ao de qualquer um dos sistemas \'e solu\c{c}\~ao do outro.
\end{definicao}

Dado um sistema linear
\begin{equation}
	\begin{cases}
		a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = b_1\\
		a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = b_2\\
		\qquad \vdots\\
		a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n = b_m\\
	\end{cases}
\end{equation}
com o objetivo de simplificar sua nota\c{c}\~ao vamos escrev\^e-lo na forma
\begin{equation}\label{formamatricial}
	AX = B
\end{equation}
onde
\begin{enumerate}
	\item
	\[
		A = \begin{bmatrix}
				a_{11} & a_{12} & \cdots & a_{1n}\\
				\vdots & & & \vdots\\
				a_{m1} & a_{m2} & \cdots & a_{mn}
			\end{bmatrix}_{m\times n}; \quad a_{ij} \in \cp{K},\ 1 \le i \le m,\ 1 \le j \le n
	\]
	\'e chamada \textbf{matriz dos coeficientes do sistema};
	\item
	\[
		X = \begin{bmatrix}
			x_1\\
			x_2\\
			\vdots\\
			x_n
		\end{bmatrix}_{n \times 1}
	\]
	\item
	\[
		B = \begin{bmatrix}
			b_1\\
			b_2\\
			\vdots\\
			b_m
		\end{bmatrix}_{m \times 1}; \quad b_1, b_2, \dots, b_m \in \cp{K}.
	\]
\end{enumerate}

Uma outra matriz que podemos associar ao sistema \eqref{sistemalinear} \'e
\[
	\begin{amatrix}{4}
		a_{11} & a_{12} & \cdots & a_{1n} & b_1\\
		a_{21} & a_{22} & \cdots & a_{2n} & b_2\\
		\vdots & \vdots & \vdots & \vdots & \vdots\\
		a_{m1} & a_{m2} & \cdots & a_{mn} & b_m\\
	\end{amatrix}
\]
que \'e chamada de \textbf{matriz ampliada do sistema} ou \textbf{matriz aumentada do sistema}.

Na forma matricial as opera\c{c}\~oes elementares s\~ao descritas como:\index{Opera\c{c}\~oes Elementares!Sobre Matrizes}
\begin{itemize}
	\item[$e_1$)] Trocar a $i$-\'esima linha de $A$ pela $j$-\'esima linha de $A$: $L_i \leftrightarrow L_j$;
	\item[$e_2$)] Multiplica\c{c}\~ao da $i$-\'esima linha de $A$ por um escalar $\alpha \in \cp{K}$ n\~ao nulo: $L_i \rightarrow \alpha L_i$;
	\item[$e_3$)] Substitui\c{c}\~ao da $i$-\'esima linha de $A$ pela $i$-\'esima linha mais $\alpha$ vezes a $j$-\'esima linha: $L_i \rightarrow L_i + \alpha L_j$.
\end{itemize}

\begin{observacao}
	Denotaremos a matriz
	\[
		\begin{bmatrix}
			0_{\cp{K}} & 0_{\cp{K}} \cdots & 0_{\cp{K}}\\
			0_{\cp{K}} & 0_{\cp{K}} \cdots & 0_{\cp{K}}\\
			\vdots & & \vdots\\
			0_{\cp{K}} & 0_{\cp{K}} \cdots & 0_{\cp{K}}
		\end{bmatrix},
	\]
	onde $0_{\cp{K}}$ \'e o elemento neutro da soma no corpo $\cp{K}$, simplesmente por $0$.
\end{observacao}

Uma raz\~ao para nos restringirmos a estes tr\^es tipos simples de opera\c{c}\~oes sobre linhas \'e que, tendo efetuado uma tal opera\c{c}\~ao $e$ sobre uma matriz $A$, podemos desfazer essa opera\c{c}\~ao efetuando uma opera\c{c}\~ao de mesmo tipo sobre $e(A)$.

\begin{teorema}
	A cada opera\c{c}\~ao elementar sobre linhas $e$, corresponde uma opera\c{c}\~ao elementar sobre linhas $e'$, do mesmo tipo que $e$, tal que $e'(e(A)) = A$ para qualquer matriz $A$. Em outras palavras, a opera\c{c}\~ao inversa de uma opera\c{c}\~ao elementar sobre linhas existe e \'e uma opera\c{c}\~ao elementar sobre linhas do mesmo tipo.
\end{teorema}
\begin{prova}
	Vamos verificar que cada uma das opera\c{c}\~oes elementares possui uma opera\c{c}\~ao inversa. Seja $A$ uma matriz $m \times n$ sobre o corpo $\cp{K}$
	\[
		A =
		\begin{bmatrix}
			a_{11} & a_{12} & \cdots & a_{1n}\\
			a_{21} & a_{22} & \cdots & a_{2n}\\
			\vdots & & & \vdots\\
			a_{m1} & a_{m2} & \cdots & a_{mn}
		\end{bmatrix}.
	\]
	\begin{enumerate}
		\item [e1)] Suponha que $e$ seja a opera\c{c}\~ao que troca a linha $i$ pela linha $j$ de $A$. Temos
		\[
			e(A) =
				\begin{bmatrix}
					a_{11} & a_{12} & \cdots & a_{1n}\\
					a_{21} & a_{22} & \cdots & a_{2n}\\
					\vdots\\
					a_{j1} & a_{j2} & \cdots & a_{jn}\\
					\vdots\\
					a_{i1} & a_{i2} & \cdots & a_{in}\\
					\vdots\\
					a_{m1} & a_{m2} & \cdots & a_{mn}
				\end{bmatrix}.
		\]
		Ent\~ao, seja $e'$ a opera\c{c}\~ao que troca a linha $i$ pela linha $j$ de $e(A)$. Assim
		\[
			e'(e(A)) = A
		\]
		como quer{\'\i}amos.

		\item [e2)] Suponha que $e$ seja a opera\c{c}\~ao que multiplica a $i$-\'esima de $A$ por $\alpha \in \cp{K}$, onde $\alpha \ne 0_\cp{K}$. Temos
		\[
			e(A) =
				\begin{bmatrix}
					a_{11} & a_{12} & \cdots & a_{1n}\\
					a_{21} & a_{22} & \cdots & a_{2n}\\
					\vdots\\
					\alpha a_{i1} & \alpha a_{i2} & \cdots & \alpha a_{in}\\
					\vdots\\
					a_{m1} & a_{m2} & \cdots & a_{mn}
				\end{bmatrix}.
		\]
		Seja $e'$ a opera\c{c}\~ao que multiplica a linha $i$ de $e(A)$ por $\alpha^{-1} \in \cp{K}$. Ent\~ao
		\[
			e'(e(A)) = A.
		\]
		\item [e3)] Suponha que $e$ seja a opera\c{c}\~ao que substitui a linha $i$ de $A$ pela linha $i$ mais $\alpha$ vezes a linha $j$. Temos
		\[
			e(A) =
				\begin{bmatrix}
					a_{11} & a_{12} & \cdots & a_{1n}\\
					a_{21} & a_{22} & \cdots & a_{2n}\\
					\vdots\\
					a_{i1} + \alpha a_{j1} & a_{i2} + \alpha a_{j2} & \cdots & a_{in} + \alpha a_{jn}\\
					\vdots\\
					a_{m1} & a_{m2} & \cdots & a_{mn}
				\end{bmatrix}.
		\]
		Seja $e'$ a opera\c{c}\~ao que substitui a linha $i$ de $e(A)$ pela linha $i$ mais $(-\alpha)$ vezes a linha $j$. Ent\~ao
		\[
			e'(e(A)) =
					\begin{bmatrix}
						a_{11} & a_{12} & \cdots & a_{1n}\\
						a_{21} & a_{22} & \cdots & a_{2n}\\
						\vdots\\
						a_{i1} + \alpha a_{j1} + (-\alpha)a_{j1} & a_{i2} + \alpha a_{j2} + (-\alpha)a_{j2} & \cdots & a_{in} + \alpha a_{jn} + (-\alpha)a_{jn}\\
						\vdots\\
						a_{m1} & a_{m2} & \cdots & a_{mn}
					\end{bmatrix}.
		\]
		e assim
		\[
			e'(e(A)) = A.
		\]
	\end{enumerate}
	Portanto cada opera\c{c}\~ao elementar sobre linhas possui uma opera\c{c}\~ao inversa.
\end{prova}

\begin{definicao}\index{Matriz!Linha Equivalente}
	Se $A$ e $B$ s\~ao matrizes $m \times n$, dizemos que $B$ \'e \textbf{linha-equivalente} a $A$, se $B$ for obtida de $A$ atrav\'es de uma quantidade finita de opera\c{c}\~oes elementares sobre as linhas de $A$.
\end{definicao}

\begin{notacao}
	$A \rightarrow B$ ou $A \sim B$.
\end{notacao}

\begin{exemplo}
	A matriz
	\[
		B =
			\begin{bmatrix}
				1 & 0\\
				0 & 1\\
				0 & 0
			\end{bmatrix}
	\]
	\'e linha equivalente \`a matriz
	\[
		A =
			\begin{bmatrix}
				\phantom{-}1 & \phantom{-}0\\
				\phantom{-}4 & -1\\
				-3 & \phantom{-}4
			\end{bmatrix}
	\]
	pois
	\begin{align*}
		A &=
			\left[
				\begin{array}{cc}
					\phantom{-}1 & \phantom{-}0\\
					\phantom{-}4 & -1\\
					-3 & \phantom{-}4
				\end{array}
			\right]
			\begin{array}{l}
				\phantom{x}\\
				L_2 \to L_2 - 4L_1\\
				\phantom{x}
			\end{array} \sim
			\left[
				\begin{array}{cc}
					\phantom{-}1 & \phantom{-}0\\
					\phantom{-}0 & -1\\
					-3 & \phantom{-}4
				\end{array}
			\right]
			\begin{array}{l}
				\phantom{x}\\
				\phantom{x}\\
				L_3 \to L_3 + 3L_1
			\end{array}\\ \\ &\sim
			\left[
				\begin{array}{cc}
					1 & \phantom{-}0\\
					0 & -1\\
					0 & \phantom{-}4
				\end{array}
			\right]
			\begin{array}{l}
				\phantom{x}\\
				L_2 \to (-1)L_2\\
				\phantom{x}
			\end{array} \sim
			\left[
				\begin{array}{cc}
					1 & 0\\
					0 & 1\\
					0 & 4
				\end{array}
			\right]
			\begin{array}{l}
				\phantom{x}\\
				\phantom{x}\\
				L_3 \to L_3 - 4L_2
			\end{array}\\ \\ &\sim
			\left[
				\begin{array}{cc}
					1 & 0\\
					0 & 1\\
					0 & 0
				\end{array}
			\right] = B.
	\end{align*}
\end{exemplo}

\begin{teorema}
	Se $X_1$ e $X_2$ s\~ao duas solu\c{c}\~oes de
	\[
	AX = 0,
	\]
	ent\~ao $\alpha X_1 + \beta X_2$ tamb\'em \'e solu\c{c}\~ao de $AX = 0$, para quaisquer $\alpha$, $\beta \in \cp{K}$.
\end{teorema}

\begin{teorema}
	Se $A$ e $B$ s\~ao matrizes $m \times n$ que s\~ao linha-equivalentes, ent\~ao os sistemas homog\^eneos de equa\c{c}\~oes lineares $AX = 0$ e $BX = 0$ t\^em exatamente as mesmas solu\c{c}\~oes.
\end{teorema}
\begin{prova}
	Suponha que podemos obter a matriz $B$ \`a partir da matriz $A$ por meio de uma sequ\^encia finita de opera\c{c}\~oes elementares sobre linhas:
	\[
	A = A_0 \sim A_1 \sim A_2 \sim \cdots \sim A_r = B.
	\]
	Nesta situa\c{c}\~ao, para provar que $AX = 0$ e $BX = 0$ tem as mesmas solu\c{c}\~oes basta provar que $A_iX = 0$ e $A_{i + 1}X = 0$ tem as mesmas solu\c{c}\~oes, isto \'e, que uma opera\c{c}\~ao elementar sobre linhas n\~ao altera o conjunto das solu\c{c}\~oes.

	Assim podemos supor que $B$ \'e obtida de $A$ por meio de uma \'unica opera\c{c}\~ao elementar. Qualquer que seja a opera\c{c}\~ao elementar, $e_1$ ou $e_2$ ou $e_3$, cada equa\c{c}\~ao do sistema $BX = 0$ ser\'a uma combina\c{c}\~ao das equa\c{c}\~oes do sistema $AX = 0$. Como a inversa de uma opera\c{c}\~ao elementar sobre linhas \'e ainda uma opera\c{c}\~ao elementar sobre linhas, cada equa\c{c}\~ao de $AX = 0$ tamb\'em ser\'a uma combina\c{c}\~ao das equa\c{c}\~oes em $BX = 0$. Logo toda solu\c{c}\~ao de $AX = 0$ tamb\'em \'e solu\c{c}\~ao de $BX = 0$ e toda solu\c{c}\~ao de $BX = 0$ tamb\'em \'e solu\c{c}\~ao de $AX = 0$, como quer{\'\i}amos.
\end{prova}

\begin{exemplo}
	Considere o sistema homog\^eneo $AX = 0$, onde:
	\begin{enumerate}[label={\arabic*})]
		\item $A = \begin{bmatrix}
						2 & -1 & \phantom{-}3 & \phantom{-}2\\
						1 & \phantom{-}4 & \phantom{-}0 & -1\\
						2 & \phantom{-}6 & -1 & \phantom{-}5
					\end{bmatrix}.$
		Para encontrar a solu\c{c}\~ao deste sistema s\'o precisamos encontrar uma matriz $B$ que seja linha equivalente \`a $A$ e que seja mais f\'acil de determinar a solu\c{c}\~ao do sistema resultante. Assim, vamos executar as opera\c{c}\~oes elementares em $A$ de modo a simplific\'a-la:
		\begin{align*}
			A &=
				\left[
					\begin{array}{cccc}
						2 & -1 & \phantom{-}3 & \phantom{-}2\\
						1 & \phantom{-}4 & \phantom{-}0 & -1\\
						2 & \phantom{-}6 & -1 & \phantom{-}5
					\end{array}
				\right]
				\begin{array}{l}
					L_1 \leftrightarrow L_2\\
					\phantom{x}\\
					\phantom{x}
				\end{array} \sim
				\left[
					\begin{array}{cccc}
						1 & \phantom{-}4 & \phantom{-}0 & -1\\
						2 & -1 & \phantom{-}3 & \phantom{-}2\\
						2 & \phantom{-}6 & -1 & \phantom{-}5
					\end{array}
				\right]
				\begin{array}{l}
					\phantom{x}\\
					L_2 \to L_2 - 2L_1\\
					L_3 \to L_3 - 2L_1
				\end{array}\\ \\ &\sim
				\left[
					\begin{array}{cccc}
						1 & \phantom{-}4 & \phantom{-}0 & -1\\
						0 & -9 & \phantom{-}3 & \phantom{-}4\\
						0 & -2 & -1 & \phantom{-}7
					\end{array}
				\right]
				\begin{array}{l}
					\phantom{x}\\
					L_2 \leftrightarrow L_3\\
					\phantom{x}
				\end{array} \sim
				\left[
					\begin{array}{cccc}
						1 & \phantom{-}4 & 0 & -1\\
						0 & -2 & -1 & \phantom{-}7\\
						0 & -9 & \phantom{-}3 & \phantom{-}4
					\end{array}
				\right]
				\begin{array}{l}
					\phantom{x}\\
					L_2 \to (-1/2)L_2\\
					\phantom{x}
				\end{array}\\ \\ &\sim
				\left[
					\begin{array}{cccc}
						1 & \phantom{-}4 & 0 & -1\\
						0 & \phantom{-}1 & 1/2 & -7/2\\
						0 & -9 & 3 & \phantom{-}4
					\end{array}
				\right]
				\begin{array}{l}
					\phantom{x}\\
					\phantom{x}\\
					L_3 \to L_3 + 9L_2
				\end{array} \sim
				\left[
					\begin{array}{cccc}
						1 & 4 & 0 & -1\\
						0 & 1 & 1/2 & -7/2\\
						0 & 0 & 15/2 & -55/2
					\end{array}
				\right]
		\end{align*}
		assim obtemos o sistema
		\[
			\begin{cases}
				x_1 + 4x_2 - x_4 = 0\\
				x_2 + (1/2)x_3 - (7/2)x_4 = 0\\
				(15/2)/x_3 - (55/2)x_4 = 0
			\end{cases}.
		\]
		Isolando $x_3$ na \'ultima equa\c{c}\~ao temos a solu\c{c}\~ao dada por
		\[
			S = \left\{\left(\dfrac{-17}{3}x_4, \dfrac{5}{3}x_4, \dfrac{11}{3}x_4, x_4\right) \mid x_4 \in \real\right\}.
		\]

		\item $A = \begin{bmatrix}
		-1 & i\\
		-i & 1\\
		\phantom{-}1 & 2
		\end{bmatrix}.$ Temos:
		\begin{align*}
			A &=
				\left[
					\begin{array}{cc}
						-1 & i\\
						-i & 1\\
						\phantom{-}1 & 2
					\end{array}
				\right]
				\begin{array}{l}
					L_1 \leftrightarrow L_3\\
					\phantom{x}\\
					\phantom{x}
				\end{array} \sim
				\left[
					\begin{array}{cc}
						\phantom{-}1 & 2\\
						-i & 1\\
						-1 & i
					\end{array}
				\right]
				\begin{array}{l}
					\phantom{x}\\
					L_2 \to L_2 + iL_1\\
					L_3 \to L_3 + L_1
				\end{array}\\ \\ &\sim
				\left[
					\begin{array}{cc}
						1 & 2\\
						0 & 1 + 2i\\
						0 & 2 + i
					\end{array}
				\right]
				\begin{array}{l}
					\phantom{x}\\
					L_2 \to \dfrac{1 - 2i}{5}L_2\\
					\phantom{x}
				\end{array} \sim
				\left[
					\begin{array}{cc}
						1 & 2\\
						0 & 1\\
						0 & 2 + i
					\end{array}
				\right]
				\begin{array}{l}
					\phantom{x}\\
					\phantom{x}\\
					L_3 \to L_3 - (2 + i)L_2
				\end{array}\\ \\ &\sim
				\left[
					\begin{array}{cc}
						1 & 2\\
						0 & 1\\
						0 & 0
					\end{array}
				\right]
		\end{align*}
		Assim obtemos o sistema
		\[
			\begin{cases}
				x_1 + 2x_2 = 0\\
				x_2 = 0
			\end{cases}
		\]
		cuja solu\c{c}\~ao \'e $x_1 = x_2 = 0$.
	\end{enumerate}
\end{exemplo}

\begin{definicao}\label{linhareduzida}\index{Matriz!Linha-reduzida}
	Uma matriz R $m \times n$ \'e chamada de \textbf{linha-reduzida} se:
	\begin{enumerate}[label={\roman*})]
		\item o primeiro elemento n\~ao nulo em cada linha n\~ao nula de $R$ \'e $1_\cp{K}$.
		\item cada coluna de $R$ que cont\'em o primeiro elemento n\~ao nulo de alguma linha tem todos os seus outros elementos nulos.
	\end{enumerate}
\end{definicao}

\begin{exemplo}
	\begin{enumerate}[label={\arabic*})]
		\item Um exemplo de uma matriz linha-reduzida \'e a matriz identidade $n \times n$. Tal matriz pode ser definida por
		\[
			I = (a_{ij})_{1 \le i,j \le n}
		\]
		onde
		\[
			a_{ij} = \delta_{ij} =
			\begin{cases}
				1, & \mbox{ se } i = j\\
				0, & \mbox{ se } i \ne j
			\end{cases}.
		\]
		O s{\'\i}mbolo $\delta_{ij}$ \'e chamada \textbf{s{\'\i}mbolo de Kronecher} \'e ser\'a utilizado com certa frequ\^encia.
		\item As matrizes
		\[
			A =
			\begin{bmatrix}
				1 & 0 & \phantom{-}0 & 0\\
				0 & 1 & -1 & 0\\
				0 & 0 & \phantom{-}1 & 0
			\end{bmatrix};\quad
			B =
			\begin{bmatrix}
				0 & 2 & \phantom{-}1\\
				1 & 0 & -3\\
				0 & 0 & \phantom{-}0
			\end{bmatrix}
		\]
		n\~ao s\~ao linha-reduzidas.
	\end{enumerate}
\end{exemplo}

\begin{teorema}
	Toda matriz $m \times n$ sobre um corpo $\cp{K}$ \'e linha-equivalente a uma matriz linha-reduzida.
\end{teorema}
\begin{prova}
	Seja $A$ uma matriz $m \times n$ sobre um corpo $\cp{K}$. Se todo elemento na primeira linha de $A$ \'e $0_\cp{K}$, ent\~ao a condi\c{c}\~ao (a) de \eqref{linhareduzida} est\'a satisfeita no que diz respeito a linha 1. Se a linha 1 tem um elemento n\~ao nulo, seja $r$ o menor inteiro positivo $j$ tal que $a_{1r} \ne 0$. Multiplique a linha 1 por $a_{1r}^{-1}$ e condi\c{c}\~ao (a) de \eqref{linhareduzida} est\'a satisfeita em rela\c{c}\~ao a linha 1. Agora, para cada $i \ge 2$, somemos $-a_{ir}$ vezes a linha 1 \`a linha i. Assim o primeiro elemento n\~ao nulo da linha 1 ocorre na coluna $r$, este elemento \'e $1_\cp{K}$, e todos os outros elementos da coluna $r$ s\~ao nulos.

	Considere agora a matriz que resultou das opera\c{c}\~oes acima. Se todo elemento na linha 2 \'e nulo, nada h\'a a fazer. Se algum elemento na linha 2 \'e n\~ao nulo, multiplicamos a linha 2 por um escalar de modo que o primeiro elemento n\~ao nulo da linha 2 seja $1_\cp{K}$. Caso o primeiro elemento n\~ao nulo da linha 1 ocorra na coluna $r$, o primeiro elemento n\~ao nulo da linha 2 n\~ao pode ocorrer na coluna $r$. Digamos ent\~ao que ele ocorra na coluna $r'$. Somando m\'ultiplos adequados da linha 2 \`as diversas linhas, podemos fazer com que todos os elementos da coluna $r'$ seja nulos, com exce\c{c}\~ao do elemento $1_\cp{K}$ da linha 2. O importante a ser observado \'e: ao efetuarmos estas \'ultimas opera\c{c}\~oes, n\~ao alteramos os elementos da linha 1 na colunas 1, 2, \dots, $r$; al\'em disso, n\~ao alteramos nenhum elemento da coluna $r$. \'E claro que, se a linha 1 fosse identicamente nula, as opera\c{c}\~oes com a linha 2 n\~ao afetariam a linha 1.

	Operando com uma linha de cada vez da maneira acima, \'e evidente que, com uma quantidade finita de passos, chegamos a uma matriz linha-reduzida.
\end{prova}

\begin{definicao}\index{Matriz!Na forma escada}
	Uma matriz $R$ $m \times n$ \'e chamada uma \textbf{matriz linha-reduzida \`a forma em escada} se:
	\begin{enumerate}[label={\roman*})]
		\item $R$ \'e linha-reduzida;
		\item toda linha de $R$ cujos elementos s\~ao todos nulos ocorre abaixo de todas as linhas que possuem um elemento n\~ao-nulo;
		\item se as linhas 1, 2, \dots, $r$ s\~ao as linhas n\~ao-nulas de $R$ e se o primeiro elemento n\~ao-nulo da linha $i$ ocorre na coluna $k_i$, $i = 1$, \dots, $r$, ent\~ao $k_1 < k_2 < \cdots < k_r$.
	\end{enumerate}
\end{definicao}

\begin{exemplo}
	\begin{enumerate}[label={\arabic*})]
		\item  A matriz identidade e a matriz nula s\~ao linha-reduzidas \`a forma escada;
		\item $\begin{bmatrix}
		1 & 0 & \phantom{-}0 & 0\\
		0 & 1 & -1 & 0\\
		0 & 0 & \phantom{-}1 & 0
		\end{bmatrix}$ N\~ao \'e linha-reduzida \`a forma escada.
		\item $\begin{bmatrix}
		0 & 2 & \phantom{-}1\\
		1 & 0 & -3\\
		0 & 0 & \phantom{-}0
		\end{bmatrix}$ N\~ao \'e linha-reduzida \`a forma escada.
		\item $\begin{bmatrix}
		0 & 1 & -3 & 0 & 2\\
		0 & 0 & \phantom{-}0 & 1 & 2\\
		0 & 0 & \phantom{-}0 & 0 & 0
		\end{bmatrix}$ \'E linha-reduzida \`a forma escada.
	\end{enumerate}
\end{exemplo}

\begin{teorema}
	Toda matriz $A$ $m \times n$ \'e linha-equivalente a uma matriz linha-reduzida \`a forma em escada.
\end{teorema}
\begin{prova}
	Sabemos que $A$ \'e linha-equivalente a uma matriz linha-reduzida. Portanto, basta notar que, efetuando uma quantidade finita de permuta\c{c}\~oes das linhas de uma matriz linha-reduzida, podemos transform\'a-la numa matriz linha-reduzida \`a forma em escada.
\end{prova}

\begin{definicao}\index{Posto!de uma matriz}\index{Nulidade!de uma matriz}
	Dada uma matriz $A$ $m \times n$, seja $B$ a matriz $m \times n$ linha-reduzida \`a forma em escada linha-equivalente a $A$. O \textbf{posto} de $A$, denotado por $p$, \'e o n\'umero de linhas n\~ao-nulas de $B$. A \textbf{nulidade} de $A$ \'e o n\'umero $n - p$.
\end{definicao}

\begin{exemplo}
	Qual o posto e a nulidade da matriz $A$, onde
	\[
		A =
		\begin{bmatrix}
			\phantom{-}1 & \phantom{-}2 & 1 & 0\\
			-1 & \phantom{-}0 & 3 & 5\\
			\phantom{-}1 & -2 & 1 & 1
		\end{bmatrix}?
	\]
	Precisamos primeiro reduzir $A$ a sua forma escada:
	\begin{align*}
		A &=
			\left[
			\begin{array}{cccc}
				\phantom{-}1 & \phantom{-}2 & 1 & 0\\
				-1 & \phantom{-}0 & 3 & 5\\
				\phantom{-}1 & -2 & 1 & 1
			\end{array}
			\right]
			\begin{array}{l}
				\\
				L_2 \to L_2 + L_1\\
				L_3 \to L_3 - L_1
			\end{array} \sim
			\left[
				\begin{array}{cccc}
					1 & \phantom{-}2 & 1 & 0\\
					0 & \phantom{-}2 & 4 & 5\\
					0 & -4 & 0 & 1
				\end{array}
			\right]
			\begin{array}{l}
				\\
				L_2 \to (1/2)L_2\\
				\phantom{x}
			\end{array}\\ \\ &\sim
			\left[
				\begin{array}{cccc}
					1 & \phantom{-}2 & 1 & 0\\
					0 & \phantom{-}1 & 2 & 5/2\\
					0 & -4 & 0 & 1
				\end{array}
			\right]
			\begin{array}{l}
				L_1 \to L_1 - 2L_2\\
				\phantom{x}\\
				L_3 \to L_3 + 4L_2
			\end{array} \sim
			\left[
				\begin{array}{cccc}
					1 & 0 & -3 & -5\\
					0 & 1 & \phantom{-}2 & \phantom{-}5/2\\
					0 & 0 & \phantom{-}8 & \phantom{-}11
				\end{array}
			\right]
			\begin{array}{l}
				\phantom{x}\\
				\phantom{x}\\
				L_3 \to (1/8)L_3
			\end{array}\\ \\ &\sim
			\left[
				\begin{array}{cccc}
					1 & 0 & -3 & -5\\
					0 & 1 & \phantom{-}2 & \phantom{-}5/2\\
					0 & 0 & \phantom{-}1 & \phantom{-}11/8
				\end{array}
			\right]
			\begin{array}{l}
				L_1 \to L_1 + 3L_3\\
				L_2 \to L_2 - 2L_3\\
				\phantom{x}
			\end{array} \sim
			\left[
				\begin{array}{cccc}
					1 & 0 & 0 & -7/8\\
					0 & 1 & 0 & -1/4\\
					0 & 0 & 1 & \phantom{-}11/8
				\end{array}
			\right]
	\end{align*}
	Logo o posto de $A$ \'e $p = 3$ e a nulidade \'e $n - p = 4 - 3 = 1$.
\end{exemplo}

Considere o sistema
\begin{equation}\label{equacaolinear}
	AX = B
\end{equation}
onde $A$ \'e uma matriz $m \times n$ e $B$ \'e uma matriz $m \times 1$, ambas com entradas no corpo $\cp{K}$ e $X$ \'e uma matriz $n \times 1$. Observe que, enquanto uma sistema homog\^eneo $AX = 0$ sempre admite a solu\c{c}\~ao
\[
x_1 = x_2 = \cdots = x_n = 0_\cp{K},
\]
um sistema n\~ao homog\^eneo pode ter:
\begin{enumerate}
	\item Uma \'unica solu\c{c}\~ao $x_1 = \alpha_1$, $x_2 = \alpha_2$, \dots, $x_n = \alpha_n$, onde $\alpha_i \in \cp{K}$, para $i = 1$, 2, \dots, $n$. Neste caso dizemos que o sistema \'e \textbf{poss{\'\i}vel e determinado}.
	\item Mais de uma solu\c{c}\~ao. Neste caso dizemos que o sistema \'e \textbf{poss{\'\i}vel e indeterminado}. Caso o corpo $\cp{K}$ tenha infinitos elementos, o sistema ter\'a infinitas solu\c{c}\~oes.
	\item Nenhuma solu\c{c}\~ao. Neste caso dizemos o que sistema \'e \textbf{imposs{\'\i}vel}.
\end{enumerate}

Com o objetivo de resolver o sistema \eqref{equacaolinear} vamos come\c{c}ar formando a matriz ampliada
\[
	P = [A|B] =
	\begin{amatrix}{4}
		a_{11} & a_{12} & \dots & a_{1n} & b_1\\
		a_{21} & a_{22} & \dots & a_{2n} & b_2\\
		\vdots & \vdots & \vdots & \vdots & \vdots\\
		a_{m1} & a_{m2} & \dots & a_{mn} & b_m\\
	\end{amatrix}_{m \times (n + 1)}.
\]

Sabemos que $P$ \'e linha-equivalente a uma matriz linha-reduzida \`a forma em escada $R$. A \'ultima coluna de $R$ cont\'em elementos $z_1$, $z_2$, \dots, $z_m$ que s\~ao resultados das opera\c{c}\~oes elementares aplicadas \`a matriz $P$. Seja
\[
	Z =
	\begin{bmatrix}
		z_1\\
		z_2\\
		\vdots\\
		z_m
	\end{bmatrix}.
\]
Ent\~ao $R$ pode ser escrita como $R = [R' \mid Z]$. Como no caso homog\^eneo, \'e poss{\'\i}vel mostrar que os sistemas
\[
	AX = B \mbox{ e } R'X = Z
\]
possuem exatamente as mesmas solu\c{c}\~oes.

As possibilidades para as solu\c{c}\~oes de tal sistema s\~ao descritas no seguinte teorema:

\begin{teorema}
	Considere o sistema
	\[
		AX = B
	\]
	onde $A$ \'e uma matriz $m \times n$ e $B$ \'e uma matriz $m \times 1$, ambas com entradas no corpo $\cp{K}$ e $X$ \'e uma matriz $n \times 1$. Ent\~ao:
	\begin{enumerate}[label={\roman*})]
		\item O sistema tem solu\c{c}\~ao se, e somente se, o posto da matriz ampliada \'e igual ao posto da matriz dos coeficientes.

		\item Se a matriz ampliada e a matriz dos coeficientes t\^em o mesmo posto $p$ e $p = n$, ent\~ao a solu\c{c}\~ao \'e \'unica.

		\item Se a matriz ampliada e a matriz dos coeficientes t\^em o mesmo posto $p$ e $p < n$, ent\~ao podemos escolher $n - p$ vari\'aveis, e as outras $p$ vari\'aveis ser\~ao dadas em fun\c{c}\~ao destas $n - p$ vari\'aveis escolhidas.
	\end{enumerate}
	O n\'umero $n - p$ \'e chamado de \textbf{grau de liberdade} e as $n - p$ vari\'aveis s\~ao chamadas de \textbf{vari\'aveis livres}.
\end{teorema}
\begin{prova}
	\textit{$1^a$ Parte: Se existe solu\c{c}\~ao para o sistema, ent\~ao a matriz ampliada e a matriz dos coeficientes t\^em o mesmo posto:} Para mostrar isso, vamos provar que se a matriz ampliada e a matriz dos coeficientes tiverem postos diferentes, ent\~ao o sistema n\~ao ter\'a solu\c{c}\~ao. Observe primeiro que o posto da matriz ampliada n\~ao pode ser menor que o posto da matriz dos coeficientes uma vez que a matriz ampliada \'e formada a partir da matriz dos coeficientes. Assim o \'unico caso poss{\'\i}vel \'e o posto da matriz ampliada ser maior que o posto da matriz dos coeficientes. Ent\~ao esta matriz, quando reduzida \`a forma em escada deve conter uma linha da forma
	\[
		\begin{bmatrix}
			0_\cp{K} & 0_\cp{K} & \cdots & 0_\cp{K} & \mid & 1_\cp{K}
		\end{bmatrix}.
	\]
	Logo o sistema associado a essa matriz tem uma equa\c{c}\~ao do tipo
	\[
		0_\cp{K}x_1 + 0_\cp{K}x_2 + \cdots + 0_\cp{K}x_n = 1_\cp{K}
	\]
	o que \'e imposs{\'\i}vel. Logo n\~ao existe solu\c{c}\~ao.

	\textit{$2^a$ Parte: Se o posto \'e igual, ent\~ao existe solu\c{c}\~ao:} Nesta situa\c{c}\~ao podem ocorrer dois casos:
	\begin{enumerate}
		\item Se $p = n$, ent\~ao a matriz linha-reduzida \`a forma em escada tem a forma
		\[
			\begin{amatrix}{5}
				1_\cp{K} & 0_\cp{K} & 0_\cp{K} & \cdots & 0_\cp{K} & z_1\\
				0_\cp{K} & 1_\cp{K} & 0_\cp{K} & \cdots & 0_\cp{K} & z_2\\
				\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
				0_\cp{K} & 0_\cp{K} & 0_\cp{K} & \cdots & 1_\cp{K} & z_n\\
				0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K}\\
				\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
				0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K}
			\end{amatrix}
		\]
		e a solu\c{c}\~ao do sistema ser\'a
		\[
			x_1 = z_1, x_2 = z_2, \cdots, x_n = z_n.
		\]
		\item Se $p \ne n$, ent\~ao devemos ter $p < n$. Caso $p > n$, como a matriz est\'a na forma escada o elemento $1_\cp{K}$ deve ocorrer em duas linhas diferentes, mas na mesma coluna. Mas neste caso, podemos anular uma destas linhas repetidas. Logo, $p < n$. Neste caso a matriz na forma escada pode ter a forma:
		\begin{enumerate}
			\item
			\[
				\begin{amatrix}{9}
					1_\cp{K} & 0_\cp{K} & 0_\cp{K} & \cdots & 0_\cp{K} & a_{1p+1} & a_{1p+2} & \cdots & a_{1n} & z_1\\
					0_\cp{K} & 1_\cp{K} & 0_\cp{K} & \cdots & 0_\cp{K} & a_{2p+1} & a_{2p+2} & \cdots & a_{2n} & z_2\\
					\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
					0_\cp{K} & 0_\cp{K} & 0_\cp{K} & \cdots & 1_\cp{K} & a_{pp+1} & a_{pp+2} & \cdots & a_{pn} & z_p\\
					0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & \cdots & 0_\cp{K} & 0_\cp{K}\\
					\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
					0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & \cdots & 0_\cp{K}  & 0_\cp{K}
				\end{amatrix}.
			\]
			Neste caso teremos
			\[
				\begin{cases}
					x_1 = z_1 + (-a_{1 p + 1})x_{p + 1} + (-a_{1 p + 2})x_{p + 2} + \cdots + (-a_{1n})x_{n}\\
					x_2 = z_2 + (-a_{2 p + 1})x_{p + 1} + (-a_{2 p + 2})x_{p + 2} + \cdots + (-a_{2n})x_{n}\\
					\qquad \vdots\\
					x_p = z_p + (-a_{p p + 1})x_{p + 1} + (-a_{p p + 2})x_{p + 2} + \cdots + (-a_{pn})x_{n}\\
				\end{cases}
			\]
			e o sistema ter\'a mais de uma solu\c{c}\~ao, sendo $x_{p + 1}$ , $x_{p + 2}$, \dots, $x_n$ as vari\'aveis livres.
			\item Uma segunda forma a ser considerada para a matriz reduzida \'e
			\[
				\begin{amatrix}{9}
					0_\cp{K} & 1_\cp{K} & 0_\cp{K} & \cdots & 0_\cp{K} & a_{1p+2} & a_{1p+3} & \cdots & a_{1n} & z_1\\
					0_\cp{K} & 0_\cp{K} & 1_\cp{K} & \cdots & 0_\cp{K} & a_{2p+2} & a_{2p+3} & \cdots & a_{2n} & z_2\\
					\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
					0_\cp{K} & 0_\cp{K} & 0_\cp{K} & \cdots & 1_\cp{K} & a_{pp+2} & a_{pp+3} & \cdots & a_{pn} & z_p\\
					0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & \cdots & 0_\cp{K} & 0_\cp{K}\\
					\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
					0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & 0_\cp{K} & \cdots & 0_\cp{K}  & 0_\cp{K}
				\end{amatrix}.
			\]
			Neste caso teremos
			\[
				\begin{cases}
					x_2 = z_1 + (-a_{1 p + 2})x_{p + 2} + (-a_{1 p + 3})x_{p + 3} + \cdots + (-a_{1n})x_{n}\\
					x_3 = z_2 + (-a_{2 p + 3})x_{p + 3} + (-a_{2 p + 3})x_{p + 3} + \cdots + (-a_{2n})x_{n}\\
					\qquad \vdots\\
					x_{p+1} = z_p + (-a_{p p + 2})x_{p + 2} + (-a_{p p + 3})x_{p + 3} + \cdots + (-a_{pn})x_{n}\\
				\end{cases}
			\]
			e o sistema ter\'a mais de uma solu\c{c}\~ao, sendo $x_1$, $x_{p + 1}$ , $x_{p + 2}$, \dots, $x_n$ as vari\'aveis livres.
		\end{enumerate}
		Prosseguindo com esse racioc{\'\i}nio, vemos que para qualquer posto $p < n$ teremos um sistema com mais de uma solu\c{c}\~ao e $n - p$ vari\'aveis livres.
	\end{enumerate}
	Portanto a condi\c{c}\~ao (i) do teorema est\'a provada.

	Observe que os itens (ii) e (iii) foram automaticamente demonstrados nos itens (a) e (b) anteriores.

	Logo o teorema est\'a provado.
\end{prova}

\begin{exemplo}
	Encontre a solu\c{c}\~ao dos seguintes sistemas lineares:
	\begin{enumerate}[label={\arabic*})]
		\item $\begin{cases}
		x + 3y + z = 0\\
		2x + 6y + 2z = 0\\
		-x - 3y - z = 0
		\end{cases}$ em $\real$.
		\begin{solucao}
		A matriz dos coeficentes deste sistema \'e
		\[
			\begin{bmatrix}
				\phantom{-}1 & \phantom{-}3 & 1\\
				\phantom{-}2 & \phantom{-}6 & 2\\
				-1 & -3 & -1
			\end{bmatrix}.
		\]
		Aplicando as opera\c{c}\~oes elementares para reduzir $A$ \`a forma em escada:
		\begin{align*}
			A &=
				\left[
					\begin{array}{ccc}
						\phantom{-}1 & \phantom{-}3 & \phantom{-}1 \\
						\phantom{-}2 & \phantom{-}6 & \phantom{-}2 \\
						-1 & -3 & -1
					\end{array}
				\right]
				\begin{array}{l}
					\\
					L_2 \to L_2 - 2L_1\\
					L_3 \to L_3 + L_1
				\end{array} \sim
				\left[
				\begin{array}{ccc}
					1 & 3 & 1 \\
					0 & 0 & 0 \\
					0 & 0 & 0
				\end{array}
				\right]
		\end{align*}
		Assim o posto de $A$ \'e $p = 1$ e a nulidade \'e 2, ou seja, temos duas vari\'aveis livres, a saber $y$ e $z$. Logo a solu\c{c}\~ao \'e dada por
		\[
			x = -3y - z;\quad y,\ z \in \real.
		\]
		Que pode ser escrita como
		\[
			S = \{(x, y ,z) \mid x, y, z \in \real \} = \{(-3y - z, y, z) \mid y, z \in \real\}.
		\]
		\end{solucao}
		\item $\begin{cases}
		\overline{1}x + \overline{4}y + \overline{2}z = \overline{6}\\
		\overline{1}x + \overline{5}y + \overline{2}z = \overline{2}\\
		\overline{2}x + \overline{3}y + \overline{4}z = \overline{4}\\
		\overline{4}x + \overline{5}y + \overline{1}z = \overline{5}
		\end{cases}$ em $\z_7$.
		\begin{solucao}
		A matriz ampliada do sistema \'e
		\[
			A =
			\begin{amatrix}{3}
				\overline{1} & \overline{4} & \overline{2} & \overline{6}\\
				\overline{1} & \overline{5} & \overline{2} & \overline{2}\\
				\overline{2} & \overline{3} & \overline{4} & \overline{4}\\
				\overline{4} & \overline{5} & \overline{1} & \overline{5}
			\end{amatrix}.
		\]
		Aplicando as opera\c{c}\~oes elementares para reduzir $A$ a forma em escada:
		\begin{align*}
			A &=
				\left[
					\begin{array}{ccc|c}
						\overline{1} & \overline{4} & \overline{2} & \overline{6}\\
						\overline{1} & \overline{5} & \overline{2} & \overline{2}\\
						\overline{2} & \overline{3} & \overline{4} & \overline{4}\\
						\overline{4} & \overline{5} & \overline{1} & \overline{5}
					\end{array}
				\right]
				\begin{array}{l}
					\\
					L_2 \to L_2 + \overline{6}L_1\\
					L_3 \to L_3 + \overline{5}L_1\\
					L_4 \to L_4 + \overline{4}L_1
				\end{array} \sim
				\left[
					\begin{array}{ccc|c}
						\overline{1} & \overline{4} & \overline{2} & \overline{6}\\
						\overline{0} & \overline{1} & \overline{0} & \overline{3}\\
						\overline{0} & \overline{2} & \overline{0} & \overline{6}\\
						\overline{0} & \overline{3} & \overline{0} & \overline{2}
					\end{array}
				\right]
				\begin{array}{l}
					L_1 \to L_1 + \overline{3}L_2\\
					\\
					L_3 \to L_3 + \overline{5}L_2\\
					L_4 \to L_4 + \overline{4}L_2
				\end{array}\\ \\ &\sim
				\left[
					\begin{array}{ccc|c}
						\overline{1} & \overline{0} & \overline{2} & \overline{1}\\
						\overline{0} & \overline{1} & \overline{0} & \overline{3}\\
						\overline{0} & \overline{0} & \overline{0} & \overline{0}\\
						\overline{0} & \overline{0} & \overline{0} & \overline{0}
					\end{array}
				\right]
		\end{align*}
		Assim o posto de $A$ \'e $p = 2$ e a nulidade \'e 1. Logo temos uma \'unica vari\'avel livre que \'e $z$. A solu\c{c}\~ao ent\~ao \'e dada por
		\[
			x = \overline{1} + \overline{5}z,\quad y = \overline{3},\quad z \in \z_7.
		\]
		O conjunto solu\c{c}\~ao \'e
		\[
			S = \{(x, y, z) \mid x, y , z \in \z_7\} = \{(\overline{1} + \overline{5}z, \overline{3}, z) \mid z \in \z_7\}.
		\]
		Tal conjunto cont\'em exatamente 7 solu\c{c}\~oes distintas.
		\end{solucao}
		\item $
		\begin{cases}
			\overline{2}x_1 + \overline{1}x_2 + \overline{2}x_3 + \overline{2}x_4 = \overline{7}\\
			\overline{3}x_1 + \overline{1}x_2 + \overline{2}x_3 + \overline{1}x_4 = \overline{9}\\
			\overline{1}x_1 + \overline{4}x_3 + \overline{3}x_4 = \overline{6}\\
			\overline{5}x_1 + \overline{1}x_3 + \overline{1}x_4 = \overline{9}
		\end{cases}$
		em $\z_{11}$.
		\begin{solucao}
		A matriz ampliada do sistema \'e
		\[
			A =
			\begin{amatrix}{4}
				\overline{2} & \overline{1} & \overline{2} & \overline{2} & \overline{7}\\
				\overline{3} & \overline{1} & \overline{2} & \overline{1} & \overline{9}\\
				\overline{1} & \overline{0} & \overline{4} & \overline{3} & \overline{6}\\
				\overline{5} & \overline{0} & \overline{1} & \overline{1} & \overline{9}
			\end{amatrix}.
		\]
		Aplicando as opera\c{c}\~oes elementares para reduzir $A$ \`a forma em escada:
		\begin{align*}
			A &=
				\left[
					\begin{array}{cccc|c}
						\overline{2} & \overline{1} & \overline{2} & \overline{2} & \overline{7}\\
						\overline{3} & \overline{1} & \overline{2} & \overline{1} & \overline{9}\\
						\overline{1} & \overline{0} & \overline{4} & \overline{3} & \overline{6}\\
						\overline{5} & \overline{0} & \overline{1} & \overline{1} & \overline{9}
					\end{array}
				\right]
				\begin{array}{l}
					L_1 \leftrightarrow L_3
				\end{array} \sim
				\left[
					\begin{array}{cccc|c}
						\overline{1} & \overline{0} & \overline{4} & \overline{3} & \overline{6}\\
						\overline{3} & \overline{1} & \overline{2} & \overline{1} & \overline{9}\\
						\overline{2} & \overline{1} & \overline{2} & \overline{2} & \overline{7}\\
						\overline{5} & \overline{0} & \overline{1} & \overline{1} & \overline{9}
					\end{array}
				\right]
				\begin{array}{l}
					\\
					L_2 \to L_2 + \overline{8}L_1\\
					L_3 \to L_3 + \overline{9}L_1\\
					L_4 \to L_4 + \overline{6}L_1
				\end{array}\\ \\ &\sim
				\left[
					\begin{array}{cccc|c}
						\overline{1} & \overline{0} & \overline{4} & \overline{3} & \overline{6}\\
						\overline{0} & \overline{1} & \overline{1} & \overline{3} & \overline{2}\\
						\overline{0} & \overline{1} & \overline{5} & \overline{7} & \overline{6}\\
						\overline{0} & \overline{0} & \overline{3} & \overline{8} & \overline{1}
					\end{array}
				\right]
				\begin{array}{l}
					\\
					\\
					L_3 \to L_3 + \overline{10}L_2\\
					\phantom{x}
				\end{array} \sim
				\left[
					\begin{array}{cccc|c}
						\overline{1} & \overline{0} & \overline{4} & \overline{3} & \overline{6}\\
						\overline{0} & \overline{1} & \overline{1} & \overline{3} & \overline{2}\\
						\overline{0} & \overline{0} & \overline{4} & \overline{4} & \overline{4}\\
						\overline{0} & \overline{0} & \overline{3} & \overline{8} & \overline{1}
					\end{array}
				\right]
				\begin{array}{l}
					\\
					\\
					L_3 \to \overline{3}L_3\\
					\phantom{x}
				\end{array}\\ \\ &\sim
				\left[
					\begin{array}{cccc|c}
						\overline{1} & \overline{0} & \overline{4} & \overline{3} & \overline{6}\\
						\overline{0} & \overline{1} & \overline{1} & \overline{3} & \overline{2}\\
						\overline{0} & \overline{0} & \overline{1} & \overline{1} & \overline{1}\\
						\overline{0} & \overline{0} & \overline{3} & \overline{8} & \overline{1}
					\end{array}
				\right]
				\begin{array}{l}
					L_1 \to L_1 + \overline{7}L_3\\
					L_2 \to L_2 + \overline{10}L_3\\
					\\
					L_4 \to L_4 + \overline{8}L_3
				\end{array} \sim
				\left[
					\begin{array}{cccc|c}
						\overline{1} & \overline{0} & \overline{0} & \overline{10} & \overline{2}\\
						\overline{0} & \overline{1} & \overline{0} & \overline{2} & \overline{1}\\
						\overline{0} & \overline{0} & \overline{1} & \overline{1} & \overline{1}\\
						\overline{0} & \overline{0} & \overline{0} & \overline{5} & \overline{9}
					\end{array}
				\right]
				\begin{array}{l}
					\\
					\\
					\\
					L_4 \to \overline{9}L_4
				\end{array}\\ \\ &\sim
				\left[
					\begin{array}{cccc|c}
						\overline{1} & \overline{0} & \overline{0} & \overline{10} & \overline{2}\\
						\overline{0} & \overline{1} & \overline{0} & \overline{2} & \overline{1}\\
						\overline{0} & \overline{0} & \overline{1} & \overline{1} & \overline{1}\\
						\overline{0} & \overline{0} & \overline{0} & \overline{1} & \overline{4}
					\end{array}
				\right]
				\begin{array}{l}
					L_1 \to L_1 + L_4\\
					L_2 \to L_2 + \overline{9}L_4\\
					L_3 \to L_3 + \overline{10}L_4\\
					\phantom{x}
				\end{array} \sim
				\left[
					\begin{array}{cccc|c}
						\overline{1} & \overline{0} & \overline{0} & \overline{0} & \overline{6}\\
						\overline{0} & \overline{1} & \overline{0} & \overline{0} & \overline{4}\\
						\overline{0} & \overline{0} & \overline{1} & \overline{0} & \overline{8}\\
						\overline{0} & \overline{0} & \overline{0} & \overline{1} & \overline{4}
					\end{array}
				\right]
		\end{align*}
		Assim o posto de $A$ \'e $p = 4$ e a nulidade \'e 0. Logo o sistema tem uma \'unica solu\c{c}\~ao dada por
		\[
			x_1 = \overline{6}, x_2 = \overline{4}, x_3 = \overline{8}, x_4 = \overline{4}.
		\]
		\end{solucao}
		\item $
		\begin{cases}
			x_1 - x_2 + 2x_3 = 4\\
			x_1 + x_3 = 6\\
			2x_1 - 3x_2 + 5x_3 = 4
		\end{cases}
		$  em $\rac$.
		\begin{solucao}
		A matriz dos coeficentes deste sistema \'e
		\[
			\begin{amatrix}{3}
				1 & -1 & 2 & 4 \\
				1 & \phantom{-}0 & 1 & 6 \\
				2 & -3 & 5 & 4
			\end{amatrix}.
		\]
		Aplicando as opera\c{c}\~oes elementares para reduzir $A$ \`a forma em escada:
		\begin{align*}
			A &=
				\left[
					\begin{array}{ccc|c}
						1 & -1 & 2 & 4 \\
						1 & \phantom{-}0 & 1 & 6 \\
						2 & -3 & 5 & 4
					\end{array}
				\right]
				\begin{array}{l}
					\\
					L_2 \to L_2 - L_1\\
					L_3 \to L_3 - 3L_1\\
				\end{array} \sim
				\left[
					\begin{array}{ccc|c}
						1 & -1 & \phantom{-}2 & \phantom{-}4 \\
						0 & \phantom{-}1 & -1 & \phantom{-}2 \\
						0 & -1 & \phantom{-}1 & -4
					\end{array}
				\right]
				\begin{array}{l}
					L_1 \to L_1 + L_2\\
					\\
					L_3 \to L_3 + L_2
				\end{array}\\ \\ &\sim
				\left[
					\begin{array}{ccc|c}
						1 & 0 & \phantom{-}1 & \phantom{-}6 \\
						0 & 1 & -1 & \phantom{-}2 \\
						0 & 0 & \phantom{-}0 & -2
					\end{array}
				\right]
		\end{align*}
		Assim o sistema n\~ao tem solu\c{c}\~ao. Note que o posto da matriz ampliada \'e $p = 3$ e a posto da matriz dos coeficientes \'e 2.
		\end{solucao}
	\end{enumerate}
\end{exemplo}
